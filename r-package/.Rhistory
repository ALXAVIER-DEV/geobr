# test
expect_equal(ncol(grid_state_correspondence_table), 3)
expect_equal(nrow(grid_state_correspondence_table), 139)
})
function_coverage(fun='grid_state_correspondence_table', test_file("tests/testthat/test-grid_state_correspondence_table.R"))
Sys.setenv(NOT_CRAN = "false")
function_coverage(fun='read_urban_area', test_file("tests/testthat/test-read_urban_area.R"))
# Check package errors
Sys.setenv(NOT_CRAN = "false")
# Check package errors
Sys.setenv(NOT_CRAN = "false")
devtools::check(pkg = ".",  cran = TRUE)
library(geobr)
read_state()
testthat::expect_output( read_state() )
read_state(code_state=9999999, year=9999999)
expect_error(read_state(code_state=9999999, year=9999999))
# Wrong year and code
testthat::expect_error(read_state(code_state=9999999, year=9999999))
context("read_state")
# skip tests because they take too much time
testthat::skip_on_cran()
test_that("read_state", {
# read data
testthat::expect_output( read_state() )
testthat::expect_output( read_state(code_state=11, year=1991) )
testthat::expect_output( read_state(code_state="AC", year=2010) )
testthat::expect_output( read_state(code_state=11, year=2010) )
testthat::expect_output( read_state(code_state="all") )
test_code <- read_state(code_state=11, year=2010)
# check sf object
expect_true(is(test_code, "sf"))
# check number of weighting areas
expect_equal(nrow(test_code), 1)
# check projection
expect_equal(sf::st_crs(test_code)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
library(testthat)
test_that("read_state", {
# read data
testthat::expect_output( read_state() )
testthat::expect_output( read_state(code_state=11, year=1991) )
testthat::expect_output( read_state(code_state="AC", year=2010) )
testthat::expect_output( read_state(code_state=11, year=2010) )
testthat::expect_output( read_state(code_state="all") )
test_code <- read_state(code_state=11, year=2010)
# check sf object
testthat::expect_true(is(test_code, "sf"))
# check number of weighting areas
testthat::expect_equal(nrow(test_code), 1)
# check projection
testthat::expect_equal(sf::st_crs(test_code)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
# ERRORS
test_that("read_state", {
# Wrong year and code
testthat::expect_error(read_state(code_state=9999999, year=9999999))
# Wrong code
testthat::expect_error( read_state(code_state=NULL, year=1991) ) # EXception
testthat::expect_error(read_state(code_state=9999999))
testthat::expect_error(read_state(code_state=5201108312313213123123123))
testthat::expect_error(read_state(code_state="AC_ABCD"))
# Wrong year
testthat::expect_error(read_state( year=9999999))
})
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun='read_state', test_file("tests/testthat/test-read_state.R"))
library(geobr)
a <- read_immediate_region()
a
b <- read_intermediate_region()
b
library(RCurl)
library(stringr)
library(sf)
library(janitor)
library(dplyr)
library(readr)
library(parallel)
library(data.table)
library(xlsx)
library(magrittr)
library(devtools)
library(lwgeom)
library(stringi)
# Root directory
root_dir <- "L:////# DIRUR #//ASMEQ//geobr//data-raw"
setwd(root_dir)
# Directory to keep raw zipped files
dir.create("./intermediate_regions")
setwd("./intermediate_regions")
# Create folders to save clean sf.rds files
destdir_clean <- "./shapes_in_sf_cleaned"
dir.create( destdir_clean , showWarnings = FALSE)
# read data
temp_sf <- st_read("RG2017_rgint.shp", quiet = F, stringsAsFactors=F, options = "ENCODING=UTF8")
temp_sf <- dplyr::rename(temp_sf, code_intermediate = rgint, name_intermediate = nome_rgint) %>%
dplyr::mutate(year = 2017,
# code_state
code_state = substr(code_intermediate,1,2),
# abbrev_state
abbrev_state =  ifelse(code_state== 11, "RO",
ifelse(code_state== 12, "AC",
ifelse(code_state== 13, "AM",
ifelse(code_state== 14, "RR",
ifelse(code_state== 15, "PA",
ifelse(code_state== 16, "AP",
ifelse(code_state== 17, "TO",
ifelse(code_state== 21, "MA",
ifelse(code_state== 22, "PI",
ifelse(code_state== 23, "CE",
ifelse(code_state== 24, "RN",
ifelse(code_state== 25, "PB",
ifelse(code_state== 26, "PE",
ifelse(code_state== 27, "AL",
ifelse(code_state== 28, "SE",
ifelse(code_state== 29, "BA",
ifelse(code_state== 31, "MG",
ifelse(code_state== 32, "ES",
ifelse(code_state== 33, "RJ",
ifelse(code_state== 35, "SP",
ifelse(code_state== 41, "PR",
ifelse(code_state== 42, "SC",
ifelse(code_state== 43, "RS",
ifelse(code_state== 50, "MS",
ifelse(code_state== 51, "MT",
ifelse(code_state== 52, "GO",
ifelse(code_state== 53, "DF",NA))))))))))))))))))))))))))),
# name_state
name_state =  ifelse(code_state== 11, "Rondônia",
ifelse(code_state== 12, "Acre",
ifelse(code_state== 13, "Amazônia",
ifelse(code_state== 14, "Roraima",
ifelse(code_state== 15, "Pará",
ifelse(code_state== 16, "Amapá",
ifelse(code_state== 17, "Tocantins",
ifelse(code_state== 21, "Maranhão",
ifelse(code_state== 22, "Piauí",
ifelse(code_state== 23, "Ceará",
ifelse(code_state== 24, "Rio Grande do Norte",
ifelse(code_state== 25, "Paraíba",
ifelse(code_state== 26, "Pernambuco",
ifelse(code_state== 27, "Alagoas",
ifelse(code_state== 28, "Sergipe",
ifelse(code_state== 29, "Bahia",
ifelse(code_state== 31, "Minas Gerais",
ifelse(code_state== 32, "Espírito Santo",
ifelse(code_state== 33, "Rio de Janeiro",
ifelse(code_state== 35, "São Paulo",
ifelse(code_state== 41, "Paraná",
ifelse(code_state== 42, "Santa Catarina",
ifelse(code_state== 43, "Rio Grande do Sul",
ifelse(code_state== 50, "Mato Grosso do Sul",
ifelse(code_state== 51, "Mato Grosso",
ifelse(code_state== 52, "Goiás",
ifelse(code_state== 53, "Distrito Federal",NA))))))))))))))))))))))))))),
# code_region
code_region = substr(code_intermediate,1,1),
# name_region
name_region = ifelse(code_region==1, 'Norte',
ifelse(code_region==2, 'Nordeste',
ifelse(code_region==3, 'Sudeste',
ifelse(code_region==4, 'Sul',
ifelse(code_region==5, 'Centro Oeste', NA))))))
# reorder columns
temp_sf <- dplyr::select(temp_sf, 'code_intermediate', 'name_intermediate','code_state', 'abbrev_state',
'name_state', 'code_region', 'name_region', 'geometry')
# Convert columns from factors to characters
temp_sf %>% dplyr::mutate_if(is.factor, as.character) -> temp_sf
# remove Z dimension of spatial data
temp_sf <- temp_sf %>% st_sf() %>% st_zm( drop = T, what = "ZM")
head(temp_sf)
# Make any invalid geometry valid # st_is_valid( sf)
temp_sf <- lwgeom::st_make_valid(temp_sf)
# Harmonize spatial projection CRS, using SIRGAS 2000 epsg (SRID): 4674
temp_sf <- if( is.na(st_crs(temp_sf)) ){ st_set_crs(temp_sf, 4674) } else { st_transform(temp_sf, 4674) }
st_crs(temp_sf) <- 4674
# keep code as.numeric()
temp_sf$code_state <- as.numeric(temp_sf$code_state)
# simplify
temp_sf_simplified <- st_transform(temp_sf, crs=3857) %>% sf::st_simplify(preserveTopology = T, dTolerance = 100) %>% st_transform(crs=4674)
# save original and simplified datasets
sf::st_write(temp_sf, paste0(destdir_clean, "/intermediate_regions_2017.gpkg") )
sf::st_write(temp_sf_simplified, paste0(destdir_clean, "/intermediate_regions_2017_simplified.gpkg") )
b <- read_intermediate_region()
b
mun2001 <- read_municipality(year=2001, code_muni = 'RJ')
i2 <- subset(mun2001, name_muni== 'Itaguaí')
i2
mun2001 <- read_municipality(year=2001, code_muni = 'RJ')
i2 <- subset(mun2001, name_muni== 'Itaguaí')
plot(i2)
head(mun2001)
mun2001 <- read_municipality(year=2001, code_muni = 'RJ')
i2 <- subset(mun2001, name_muni== 'Itaguaí')
i2
a <- read_municipality(year=1991)
a
a <- read_municipality(year=0000)
View(a)
b<- read_municipality(year=2000)
View(a)
a <- read_municipal_seat(year=1991)
a
a <- read_municipal_seat(year=0000)
a <- read_municipal_seat(year=2000)
a <- read_municipal_seat(year=2010)
a
a <- read_municipal_seat(year=1991)
a
a <- read_municipal_seat(year=1980)
a
library(geobr)
library(geobr)
a <- read_amazon(year=2012)
a <- read_amazon(year=2012, tp=1)
a <- read_amazon(year=2012, tp='a')
library(geobr)
rm(list = ls())
library(roxygen2)
library(devtools)
library(usethis)
library(testthat)
library(usethis)
# Check package errors
Sys.setenv(NOT_CRAN = "false")
devtools::check(pkg = ".",  cran = TRUE)
library(geobr)
library(sf)
library(dplyr)
library(rio)
# Available data sets
datasets <- list_geobr()
print(datasets, n=21)
# State of Sergige
state <- read_state(code_state="SE", year=2018)
state <- read_state(code_state="SE", year=2018)
mun <- read_municipality(code_muni="all", year=2018)
read_municipality <- function(code_muni="all", year=2010, simplified=TRUE, showProgress=TRUE, tp){
# deprecated 'tp' argument
if (!missing("tp")){stop(" 'tp' argument deprecated. Please use argument 'simplified' TRUE or FALSE")}
# Get metadata with data url addresses
temp_meta <- select_metadata(geography="municipality", year=year, simplified=simplified)
# BLOCK 2.1 From 1872 to 1991  ----------------------------
if( year < 1992){
# list paths of files to download
file_url <- as.character(temp_meta$download_path)
# download files
temp_sf <- download_gpkg(file_url, progress_bar = showProgress)
return(temp_sf)
} else {
# BLOCK 2.2 From 2000 onwards  ----------------------------
# 2.2 Verify code_muni Input
# if code_muni=="all", read the entire country
if(code_muni=="all"){ message("Loading data for the whole country. This might take a few minutes.\n")
# list paths of files to download
file_url <- as.character(temp_meta$download_path)
# download files
temp_sf <- download_gpkg(file_url, progress_bar = showProgress)
return(temp_sf)
}
else if( !(substr(x = code_muni, 1, 2) %in% temp_meta$code) & !(substr(x = code_muni, 1, 2) %in% temp_meta$code_abrev)){
stop("Error: Invalid Value to argument code_muni.")
} else{
# list paths of files to download
if (is.numeric(code_muni)){ file_url <- as.character(subset(temp_meta, code==substr(code_muni, 1, 2))$download_path) }
if (is.character(code_muni)){ file_url <- as.character(subset(temp_meta, code_abrev==substr(code_muni, 1, 2))$download_path) }
# download files
sf <- download_gpkg(file_url, progress_bar = showProgress)
# input is a state code
if(nchar(code_muni)==2){
return(sf) }
# input is a municipality code
else if(code_muni %in% sf$code_muni){
x <- code_muni
sf <- subset(sf, code_muni==x)
return(sf)
} else{
stop("Error: Invalid Value to argument code_muni.")
}
}
}
}
mun <- read_municipality(code_muni="all", year=2018)
}
library(geobr)
warnings()
library(geobr)
# Check package errors
Sys.setenv(NOT_CRAN = "false")
devtools::check(pkg = ".",  cran = TRUE)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
system.time(  geobr_cov <- covr::package_coverage() )
geobr_cov
beepr::beep()
geobr_cov
testthat::expect_error(read_amazon(tp="xxx"))
function_coverage(fun= 'read_amazon', test_file("tests/testthat/test-read_amazon.R"))
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun= 'read_amazon', test_file("tests/testthat/test-read_amazon.R"))
library(geobr)
install.packages("rmapshaper")
library(geobr)
library(magrittr)
library(sf)
library(beepr)
library(pbapply)
library(furrr)
library(mapview)
library(magrittr)
library(data.table)
# list all simplified data sets
simplified_files <- list.files(path = '//storage1/geobr/data_gpkg', recursive = T, full.names = T)
simplified_files
simplified_files[simplified_files %like% 'health_facilities']
simplified_files[simplified_files %like% 'health_facilities|lookup_muni']
simplified_files[simplified_files %like% 'health_facilities|lookup_muni|municipal_seat']
simplified_files[!(simplified_files %like% 'health_facilities|lookup_muni|municipal_seat')]
# data that are not polygons should not be processed
simplified_files_30 <- simplified_files[!(simplified_files %like% 'health_facilities|lookup_muni|municipal_seat')]
# list all simplified data sets
simplified_files <- list.files(path = '//storage1/geobr/data_gpkg', recursive = T, full.names = T)
# data that are not polygons should not be processed
simplified_files <- simplified_files[!(simplified_files %like% 'health_facilities|lookup_muni|municipal_seat')]
simplified_files <- simplified_files[1]
simplified_files
message(file_address)
# list all simplified data sets
simplified_files <- list.files(path = '//storage1/geobr/data_gpkg', recursive = T, full.names = T)
# data that are not polygons should not be processed
simplified_files <- simplified_files[!(simplified_files %like% 'health_facilities|lookup_muni|municipal_seat')]
file_address <- simplified_files[1]
message(file_address)
# get address of original file
simplified_file_address <- file_address
simplified_file_address
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
class(temp_gpkg)
st_geometry_type(temp_gpkg) %>% unique()
st_geometry_type(temp_gpkg) %>% unique() %>% as.character()
st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"))
# list all simplified data sets
all_files <- list.files(path = '//storage1/geobr/data_gpkg', recursive = T, full.names = T)
# list all simplified data sets
all_files <- list.files(path = '//storage1/geobr/data_gpkg', recursive = T, full.names = T)
# data that are not polygons should not be processed
polygon_files <- all_files[!(all_files %like% 'health_facilities|lookup_muni|municipal_seat')]
file_address <- polygon_files[1]
file_address
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON")))
message(paste('jumping ', file_address ))
multipolygon_gpkg <- function(file_address){
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
# make everything a MULTIPOLYGON
if( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"))) {
temp_gpkg <- sf::st_cast(temp_gpkg, "MULTIPOLYGON")
# delete previous file
message('deleting old file')
file.remove(file_address)
# save simplified file
message('saving new file')
sf::st_write(temp_gpkg, file_address, quiet = TRUE)
} else{
message(paste('jumping ', file_address ))
return(NULL)}
}
multipolygon_gpkg( polygon_files[1])
multipolygon_gpkg( polygon_files[2])
polygon_files
file_address <- polygon_files[3]
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON")))
multipolygon_gpkg( polygon_files[59])
polygon_files[58]
file_address <- polygon_files[58]
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON")))
st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length()
st_geometry_type(temp_gpkg) %>% unique() %>% as.character()
st_geometry_type(temp_gpkg) %>% unique() %>% as.character()
file_address <- polygon_files[58]
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON")))
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
# make everything a MULTIPOLYGON
if( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"))) {
temp_gpkg <- sf::st_cast(temp_gpkg, "MULTIPOLYGON")
# delete previous file
message('deleting old file')
file.remove(file_address)
# save simplified file
message('saving new file')
sf::st_write(temp_gpkg, file_address, quiet = TRUE)
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
# make everything a MULTIPOLYGON
if( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"))) {
temp_gpkg <- sf::st_cast(temp_gpkg, "MULTIPOLYGON")
# delete previous file
message('deleting old file')
file.remove(file_address)
# save simplified file
message('saving new file')
sf::st_write(temp_gpkg, file_address, quiet = TRUE)
}
file_address
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON")))
polygon_files[56]
polygon_files[55]
polygon_files[54]
file_address <- polygon_files[54]
file_address
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
# make everything a MULTIPOLYGON
if( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"))) {
temp_gpkg <- sf::st_cast(temp_gpkg, "MULTIPOLYGON")
# delete previous file
message('deleting old file')
file.remove(file_address)
# save simplified file
message('saving new file')
sf::st_write(temp_gpkg, file_address, quiet = TRUE)
}
file_address
polygon_files[53]
file_address <- polygon_files[53]
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON")))
st_geometry_type(temp_gpkg) %>% unique() %>% as.character()
st_geometry_type(temp_gpkg) %>% unique() %>% as.character()
st_geometry_type(temp_gpkg) %>% unique() %>% as.character()
st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON")
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"))
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"))
temp_gpkg <- sf::st_cast(temp_gpkg, "MULTIPOLYGON")
multipolygon_gpkg <- function(file_address){
# file_address <- polygon_files[53]
message(file_address)
# read original file
temp_gpkg <- sf::st_read(file_address, quiet=T)
# make everything a MULTIPOLYGON
if( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %>% length() > 1 |
any(  !( st_geometry_type(temp_gpkg) %>% unique() %>% as.character() %like% "MULTIPOLYGON"))) {
temp_gpkg <- sf::st_cast(temp_gpkg, "MULTIPOLYGON")
# delete previous file
message('deleting old file')
file.remove(file_address)
# save simplified file
message('saving new file')
sf::st_write(temp_gpkg, file_address, quiet = TRUE)
} else{
message(paste('jumping ', file_address ))
return(NULL)}
}
# list all simplified data sets
all_files <- list.files(path = '//storage1/geobr/data_gpkg', recursive = T, full.names = T)
# data that are not polygons should not be processed
polygon_files <- all_files[!(all_files %like% 'health_facilities|lookup_muni|municipal_seat')]
all_files[ all_files %like% 'state/2018']
polygon_files <- all_files[ all_files %like% 'state/2018']
pbapply::pblapply(X=polygon_files, FUN = multipolygon_gpkg)
# list all simplified data sets
all_files <- list.files(path = '//storage1/geobr/data_gpkg', recursive = T, full.names = T)
# data that are not polygons should not be processed
polygon_files <- all_files[!(all_files %like% 'health_facilities|lookup_muni|municipal_seat')]
lookup_muni('manaus')
polygon_files <- all_files[ all_files %like% 'census_tract/2010/13']
polygon_files
polygon_files
polygon_files
# i core
pbapply::pblapply(X=polygon_files, FUN = multipolygon_gpkg)
