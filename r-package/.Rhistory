library(data.table)
library(geobr)
project_wd <- getwd()
###### 0. Create Root folder to save the data -----------------
# Root directory
root_dir <- "L:\\# DIRUR #\\ASMEQ\\geobr\\data-raw"
setwd(root_dir)
# Directory to keep raw zipped files
dir.create("./lookup_muni")
destdir_raw <- paste0("./lookup_muni/",update)
dir.create(destdir_raw)
destdir_raw
# Open lookup table with munis
lookup_munis <- fread("lookup_muni/tabela_muni_codigos_2010.csv")
lookup_munis
# convert encoding
lookup_munis <- lookup_munis %>%
mutate_at(vars(matches("nome")), stringi::stri_encode, to = "UTF8")
# save and open again to make sure it's ok
write_csv(lookup_munis, "lookup_muni/lookup_munis_utf8.csv")
lookup_munis <- fread("lookup_muni/lookup_munis_utf8.csv", encoding = "UTF-8")
# Download munis
munis <- geobr::read_municipality(code_muni = "all", year = 2010) %>%
# select necessary columns
select(code_muni)
# Download intermediate information
intermediates <- geobr::read_intermediate_region(code_intermediate = "all") %>%
# # delete geometry
# st_set_geometry(NULL) %>%
# select necessary columns
select(code_intermediate, name_intermediate)
# Download immediate information
immediates <- geobr::read_immediate_region(code_immediate = "all") %>%
# # delete geometry
# st_set_geometry(NULL) %>%
# select necessary columns
select(code_immediate, name_immediate)
# Join munis to intermediates
lookup1 <- st_join(munis, intermediates, largest = TRUE)
# Join munis to immediates
lookup2 <- st_join(lookup1, immediates, largest = TRUE)
# Join munis to intermediates
lookup1 <- st_join(munis, intermediates, largest = TRUE)
sf::st_is_valid(munis)
intermediates <- lwgeom::st_make_valid(intermediates)
munis <- lwgeom::st_make_valid(munis)
immediates <- lwgeom::st_make_valid(immediates)
# Join munis to intermediates
lookup1 <- st_join(munis, intermediates, largest = TRUE)
# Join munis to immediates
lookup2 <- st_join(lookup1, immediates, largest = TRUE)
# Delete geometry
lookup2_nogeo <- st_set_geometry(lookup2, NULL)
# Bring new information to lookup_munis
lookup_end <- lookup_munis %>%
left_join(lookup2_nogeo, by = c("municipio" = "code_muni")) %>%
# rename variables to match geobr convention
select(code_muni = municipio, name_muni = nome_municipio,
code_state = uf, name_state = nome_uf,
code_micro = microregiao, name_micro = nome_microregiao,
code_meso = mesoregiao, name_meso = nome_mesorregiao,
code_immediate, name_immediate,
code_intermediate, name_intermediate)
head(lookup_end)
write_csv(lookup_end, "lookup_muni/lookup_muni_2010_unformatted.csv")
# create empty metadata
metadata <- data.frame(matrix(ncol = 5, nrow = 0))
colnames(metadata) <- c("geo","year","code","download_path","code_abrev")
# list all data files available in the geobr package
geo=list.files("//storage1/geobr/data_gpkg")
# populate the metadata table
for (a in geo) {    # a="setor_censitario"
ano=list.files(paste("//storage1/geobr/data_gpkg",a,sep="/"))
for (b in ano) { # b=2000
estado=list.files(paste("//storage1/geobr/data_gpkg",a,b,sep="/"))
for (c in estado) { #c="Urbano"
if (c=="Urbano"|c=="Rural"){
estado2=list.files(paste("//storage1/geobr/data_gpkg",a,b,c,sep="/"))
for (d in estado2) { #d=estado2[1]
if (c=="Urbano") {
metadata[nrow(metadata) + 1,] = list(a,b,paste0("U",substr(d, 1, 2)),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,d,sep="/"))
}
if (c=="Rural") {
metadata[nrow(metadata) + 1,] = list(a,b,paste0("R",substr(d, 1, 2)),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,d,sep="/"))
}
}
} else {
metadata[nrow(metadata) + 1,] = list(a,b,substr(c, 1, 2),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,sep="/"))}
}
}
}
# table(metadata$geo)
# temp_ano <- subset(metadata, geo=="biomes")
# temp_ano <- subset(metadata, geo=="country")
# get code abbreviations
library(data.table)
setDT(metadata)
metadata[ grepl("11", substr(code, 1, 3)), code_abrev :=	"RO" ]
metadata[ grepl("12", substr(code, 1, 3)), code_abrev :=	"AC" ]
metadata[ grepl("13", substr(code, 1, 3)), code_abrev :=	"AM" ]
metadata[ grepl("14", substr(code, 1, 3)), code_abrev :=	"RR" ]
metadata[ grepl("15", substr(code, 1, 3)), code_abrev :=	"PA" ]
metadata[ grepl("16", substr(code, 1, 3)), code_abrev :=	"AP" ]
metadata[ grepl("17", substr(code, 1, 3)), code_abrev :=	"TO" ]
metadata[ grepl("21", substr(code, 1, 3)), code_abrev :=	"MA" ]
metadata[ grepl("22", substr(code, 1, 3)), code_abrev :=	"PI" ]
metadata[ grepl("23", substr(code, 1, 3)), code_abrev :=	"CE" ]
metadata[ grepl("24", substr(code, 1, 3)), code_abrev :=	"RN" ]
metadata[ grepl("25", substr(code, 1, 3)), code_abrev :=	"PB" ]
metadata[ grepl("26", substr(code, 1, 3)), code_abrev :=	"PE" ]
metadata[ grepl("27", substr(code, 1, 3)), code_abrev :=	"AL" ]
metadata[ grepl("28", substr(code, 1, 3)), code_abrev :=	"SE" ]
metadata[ grepl("29", substr(code, 1, 3)), code_abrev :=	"BA" ]
metadata[ grepl("31", substr(code, 1, 3)), code_abrev :=	"MG" ]
metadata[ grepl("32", substr(code, 1, 3)), code_abrev :=	"ES" ]
metadata[ grepl("33", substr(code, 1, 3)), code_abrev :=	"RJ" ]
metadata[ grepl("35", substr(code, 1, 3)), code_abrev :=	"SP" ]
metadata[ grepl("41", substr(code, 1, 3)), code_abrev :=	"PR" ]
metadata[ grepl("42", substr(code, 1, 3)), code_abrev :=	"SC" ]
metadata[ grepl("43", substr(code, 1, 3)), code_abrev :=	"RS" ]
metadata[ grepl("50", substr(code, 1, 3)), code_abrev :=	"MS" ]
metadata[ grepl("51", substr(code, 1, 3)), code_abrev :=	"MT" ]
metadata[ grepl("52", substr(code, 1, 3)), code_abrev :=	"GO" ]
metadata[ grepl("53", substr(code, 1, 3)), code_abrev :=	"DF" ]
# to avoid conflict with data.table
metadata <- as.data.frame(metadata)
table(metadata$geo)
table(metadata$year)
readr::write_csv(metadata,"//storage1/geobr/metadata/metadata_gpkg.csv")
# Get metadata with data addresses
metadata <- download_metadata()
# Open lookup table
temp_meta <- subset(metadata, geo == "lookup_muni")
temp_meta
library(geobr)
# Get metadata with data addresses
metadata <- download_metadata()
# Open lookup table
temp_meta <- subset(metadata, geo == "lookup_muni")
temp_meta
# download files
temps <- paste0(tempdir(),"/", unlist(lapply(strsplit(filesD,"/"),tail,n=1L)))
# list paths of files to download
filesD <- as.character(temp_meta$download_path)
# download files
temps <- paste0(tempdir(),"/", unlist(lapply(strsplit(filesD,"/"),tail,n=1L)))
httr::GET(url=filesD, httr::progress(), httr::write_disk(temps, overwrite = T))
# read file
lookup_table_2010 <- utils::read.csv(temps, stringsAsFactors = F)
lookup_table_2010
# read file
lookup_table_2010 <- utils::read.csv(temps, stringsAsFactors = F, encoding = 'UTF8')
lookup_table_2010
update <- 2010
library(RCurl)
library(stringr)
library(sf)
library(dplyr)
library(readr)
library(data.table)
library(geobr)
project_wd <- getwd()
###### 0. Create Root folder to save the data -----------------
# Root directory
root_dir <- "L:\\# DIRUR #\\ASMEQ\\geobr\\data-raw"
setwd(root_dir)
# Directory to keep raw zipped files
dir.create("./lookup_muni")
destdir_raw <- paste0("./lookup_muni/",update)
dir.create(destdir_raw)
# # Create folders to save clean sf.rds files  -----------------
# dir.create("./biomes/shapes_in_sf_cleaned", showWarnings = FALSE)
# destdir_clean <- paste0("./biomes/shapes_in_sf_cleaned/",update)
# dir.create(destdir_clean)
update=2010
# Get metadata with data addresses
metadata <- download_metadata()
# Open lookup table
temp_meta <- subset(metadata, geo == "lookup_muni")
# list paths of files to download
filesD <- as.character(temp_meta$download_path)
# download files
temps <- paste0(tempdir(),"/", unlist(lapply(strsplit(filesD,"/"),tail,n=1L)))
httr::GET(url=filesD, httr::progress(), httr::write_disk(temps, overwrite = T))
# read file
lookup_table_2010 <- utils::read.csv(temps, stringsAsFactors = F, encoding = 'UTF-8')
lookup_table_2010
# Open lookup table with munis
lookup_munis <- fread("lookup_muni/tabela_muni_codigos_2010.csv")
# convert encoding
lookup_munis <- lookup_munis %>%
mutate_at(vars(matches("nome")), stringi::stri_encode, to = "UTF8")
# save and open again to make sure it's ok
write_csv(lookup_munis, "lookup_muni/lookup_munis_utf8.csv")
lookup_munis <- fread("lookup_muni/lookup_munis_utf8.csv", encoding = "UTF-8")
# Download munis
munis <- geobr::read_municipality(code_muni = "all", year = 2010) %>%
# select necessary columns
select(code_muni)
# # Download regions
# regions <- geobr::read_region(year = 2010)
#
# # Download meso regions
# meso_region <- geobr::read_meso_region(code_meso = "all", year = 2010)
#
# # Download micro regions
# micro_regions <- geobr::read_micro_region(code_micro = "all", year = 2010)
# Download intermediate information
intermediates <- geobr::read_intermediate_region(code_intermediate = "all") %>%
# # delete geometry
# st_set_geometry(NULL) %>%
# select necessary columns
select(code_intermediate, name_intermediate)
# Download immediate information
immediates <- geobr::read_immediate_region(code_immediate = "all") %>%
# # delete geometry
# st_set_geometry(NULL) %>%
# select necessary columns
select(code_immediate, name_immediate)
# fix eventual topology errors
intermediates <- lwgeom::st_make_valid(intermediates)
immediates <- lwgeom::st_make_valid(immediates)
munis <- lwgeom::st_make_valid(munis)
# Join munis to intermediates
lookup1 <- st_join(munis, intermediates, largest = TRUE)
# Join munis to immediates
lookup2 <- st_join(lookup1, immediates, largest = TRUE)
# Delete geometry
lookup2_nogeo <- st_set_geometry(lookup2, NULL)
# Bring new information to lookup_munis
lookup_end <- lookup_munis %>%
left_join(lookup2_nogeo, by = c("municipio" = "code_muni")) %>%
# rename variables to match geobr convention
select(code_muni = municipio, name_muni = nome_municipio,
code_state = uf, name_state = nome_uf,
code_micro = microregiao, name_micro = nome_microregiao,
code_meso = mesoregiao, name_meso = nome_mesorregiao,
code_immediate, name_immediate,
code_intermediate, name_intermediate)
head(lookup_end)
encodeString(lookup_end$name_muni)
guess_encoding(lookup_end, n_max = 10000, threshold = 0.2)
encodeString(lookup_end$name_muni)
sapply(lookup_end, class)
lookup_end <- lookup_end %>% mutate_if(is.factor, function(x){ x %>% as.character() %>% stringi::stri_encode("UTF-8") } )
lookup_end <- lookup_end %>% mutate_if(is.character, function(x){ x %>% stringi::stri_encode("UTF-8") } )
warnings()
guess_encoding(lookup_end, n_max = 10000, threshold = 0.2)
# Bring new information to lookup_munis
lookup_end <- lookup_munis %>%
left_join(lookup2_nogeo, by = c("municipio" = "code_muni")) %>%
# rename variables to match geobr convention
select(code_muni = municipio, name_muni = nome_municipio,
code_state = uf, name_state = nome_uf,
code_micro = microregiao, name_micro = nome_microregiao,
code_meso = mesoregiao, name_meso = nome_mesorregiao,
code_immediate, name_immediate,
code_intermediate, name_intermediate)
head(lookup_end)
head(lookup_end)
guess_encoding(lookup_end, n_max = 50, threshold = 0.2)
# Use UTF-8 encoding in all character columns
lookup_end <- lookup_end %>% mutate_if(is.factor, function(x){ x %>% as.character() %>% stringi::stri_encode("UTF-8") } )
lookup_end <- lookup_end %>% mutate_if(is.character, function(x){ x %>% as.character() %>% stringi::stri_encode("UTF-8") } )
warnings()
head(lookup_end)
# Bring new information to lookup_munis
lookup_end <- lookup_munis %>%
left_join(lookup2_nogeo, by = c("municipio" = "code_muni")) %>%
# rename variables to match geobr convention
select(code_muni = municipio, name_muni = nome_municipio,
code_state = uf, name_state = nome_uf,
code_micro = microregiao, name_micro = nome_microregiao,
code_meso = mesoregiao, name_meso = nome_mesorregiao,
code_immediate, name_immediate,
code_intermediate, name_intermediate)
head(lookup_end)
sapply(lookup_end, class)
# Use UTF-8 encoding in all character columns
lookup_end <- lookup_end %>% mutate_if(is.factor, function(x){ x %>% as.character() %>% stringi::stri_encode("UTF-8") } )
sapply(lookup_end, class)
guess_encoding(lookup_end, n_max = 50, threshold = 0.2)
# Bring new information to lookup_munis
lookup_end <- lookup_munis %>%
left_join(lookup2_nogeo, by = c("municipio" = "code_muni")) %>%
# rename variables to match geobr convention
select(code_muni = municipio, name_muni = nome_municipio,
code_state = uf, name_state = nome_uf,
code_micro = microregiao, name_micro = nome_microregiao,
code_meso = mesoregiao, name_meso = nome_mesorregiao,
code_immediate, name_immediate,
code_intermediate, name_intermediate)
# Save unformatted
write_csv(lookup_end, "lookup_muni/lookup_muni_2010_unformatted.csv")
# Open unformatted lookup muni
lookup_end <- read_csv("lookup_muni/lookup_muni_2010_unformatted.csv")
lookup_end
lookup_end_format <- lookup_end %>%
# to lower
mutate(name_muni_format = tolower(name_muni)) %>%
# delete accents
mutate(name_muni_format = stringi::stri_trans_general(name_muni_format, id = "Latin-ASCII")) %>%
mutate(name_muni_format = iconv(name_muni_format, to="UTF-8")) %>%
# trim white spaces
mutate(name_muni_format = trimws(name_muni_format, "both"))
lookup_state <- data.frame(name_uf = c("Acre", "Alagoas", "Amapá", "Amazonas", "Bahia", "Ceará", "Distrito Federal", "Espírito Santo",
"Goiás", "Maranhão", "Mato Grosso", "Mato Grosso do Sul", "Minas Gerais",
"Pará", "Paraíba", "Paraná", "Pernanbuco", "Piauí", "Rio de Janeiro",
"Rio Grande do Norte", "Rio Grande do Sul", "Rondônia", "Roraima",
"Santa Catarina", "São Paulo", "Sergipe", "Tocantins"),
abrev_state = c("AC", "AL", "AM", "AP", "BA", "CE", "DF", "ES", "GO", "MA", "MG", "MS",
"MT", "PA", "PB", "PE", "PI", "PR", "RJ", "RN", "RO", "RR",
"RS", "SC", "SE", "SP", "TO"))
# bring abrev state
lookup_end_format <- lookup_end_format %>%
left_join(lookup_state, by = c("name_state" = "name_uf"))
# organize columns
lookup_end_format <- lookup_end_format %>%
select(code_muni, name_muni,
code_state, name_state, abrev_state,
code_micro, name_micro,
code_meso, name_meso,
code_immediate, name_immediate,
code_intermediate, name_intermediate,
name_muni_format)
lookup_end_format <- lookup_end_format %>%
mutate_if(is.factor, function(x){ x %>% as.character() %>%
stringi::stri_encode("UTF-8") } ) %>%
mutate_if(is.character, function(x){ x %>%
stringi::stri_encode("UTF-8") } )
lookup_end_format
write_csv(lookup_end_format, "lookup_muni/2010/lookup_muni_2010.csv")
guess_encoding(lookup_end_format, n_max = 10000, threshold = 0.2)
head(lookup_end_format)
######### Etapa 1 - bases padrao ( geo/ano/arquivo) ----------------------
# create empty metadata
metadata <- data.frame(matrix(ncol = 5, nrow = 0))
colnames(metadata) <- c("geo","year","code","download_path","code_abrev")
# list all data files available in the geobr package
geo=list.files("//storage1/geobr/data_gpkg")
# populate the metadata table
for (a in geo) {    # a="setor_censitario"
ano=list.files(paste("//storage1/geobr/data_gpkg",a,sep="/"))
for (b in ano) { # b=2000
estado=list.files(paste("//storage1/geobr/data_gpkg",a,b,sep="/"))
for (c in estado) { #c="Urbano"
if (c=="Urbano"|c=="Rural"){
estado2=list.files(paste("//storage1/geobr/data_gpkg",a,b,c,sep="/"))
for (d in estado2) { #d=estado2[1]
if (c=="Urbano") {
metadata[nrow(metadata) + 1,] = list(a,b,paste0("U",substr(d, 1, 2)),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,d,sep="/"))
}
if (c=="Rural") {
metadata[nrow(metadata) + 1,] = list(a,b,paste0("R",substr(d, 1, 2)),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,d,sep="/"))
}
}
} else {
metadata[nrow(metadata) + 1,] = list(a,b,substr(c, 1, 2),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,sep="/"))}
}
}
}
# table(metadata$geo)
# temp_ano <- subset(metadata, geo=="biomes")
# temp_ano <- subset(metadata, geo=="country")
# get code abbreviations
library(data.table)
setDT(metadata)
metadata[ grepl("11", substr(code, 1, 3)), code_abrev :=	"RO" ]
metadata[ grepl("12", substr(code, 1, 3)), code_abrev :=	"AC" ]
metadata[ grepl("13", substr(code, 1, 3)), code_abrev :=	"AM" ]
metadata[ grepl("14", substr(code, 1, 3)), code_abrev :=	"RR" ]
metadata[ grepl("15", substr(code, 1, 3)), code_abrev :=	"PA" ]
metadata[ grepl("16", substr(code, 1, 3)), code_abrev :=	"AP" ]
metadata[ grepl("17", substr(code, 1, 3)), code_abrev :=	"TO" ]
metadata[ grepl("21", substr(code, 1, 3)), code_abrev :=	"MA" ]
metadata[ grepl("22", substr(code, 1, 3)), code_abrev :=	"PI" ]
metadata[ grepl("23", substr(code, 1, 3)), code_abrev :=	"CE" ]
metadata[ grepl("24", substr(code, 1, 3)), code_abrev :=	"RN" ]
metadata[ grepl("25", substr(code, 1, 3)), code_abrev :=	"PB" ]
metadata[ grepl("26", substr(code, 1, 3)), code_abrev :=	"PE" ]
metadata[ grepl("27", substr(code, 1, 3)), code_abrev :=	"AL" ]
metadata[ grepl("28", substr(code, 1, 3)), code_abrev :=	"SE" ]
metadata[ grepl("29", substr(code, 1, 3)), code_abrev :=	"BA" ]
metadata[ grepl("31", substr(code, 1, 3)), code_abrev :=	"MG" ]
metadata[ grepl("32", substr(code, 1, 3)), code_abrev :=	"ES" ]
metadata[ grepl("33", substr(code, 1, 3)), code_abrev :=	"RJ" ]
metadata[ grepl("35", substr(code, 1, 3)), code_abrev :=	"SP" ]
metadata[ grepl("41", substr(code, 1, 3)), code_abrev :=	"PR" ]
metadata[ grepl("42", substr(code, 1, 3)), code_abrev :=	"SC" ]
metadata[ grepl("43", substr(code, 1, 3)), code_abrev :=	"RS" ]
metadata[ grepl("50", substr(code, 1, 3)), code_abrev :=	"MS" ]
metadata[ grepl("51", substr(code, 1, 3)), code_abrev :=	"MT" ]
metadata[ grepl("52", substr(code, 1, 3)), code_abrev :=	"GO" ]
metadata[ grepl("53", substr(code, 1, 3)), code_abrev :=	"DF" ]
# to avoid conflict with data.table
metadata <- as.data.frame(metadata)
table(metadata$geo)
table(metadata$year)
subset(metadata, geo == 'metropolitan_area')
readr::write_csv(metadata,"//storage1/geobr/metadata/metadata_gpkg.csv")
# Get metadata with data addresses
metadata <- download_metadata()
# Open lookup table
temp_meta <- subset(metadata, geo == "lookup_muni")
temp_meta
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# Load geobr and other libraries we'll use
library(geobr)
library(ggplot2)
library(sf)
library(dplyr)
library(rio)
# download data
state <- read_state(code_state="SE", year=2018)          # State
micro <- read_micro_region(code_micro=160101, year=2000) # Micro region
# download data
meso <- read_meso_region(code_meso="PA", year=2018)      # Meso region
muni <- read_municipality(code_muni= "AL", year=2007)    # Municipality
# download data
state <- read_state(code_state="all", year=1991)         # State
meso <- read_meso_region(code_meso="all", year=2001)     # Meso region
# No plot axis
no_axis <- theme(axis.title=element_blank(),
axis.text=element_blank(),
axis.ticks=element_blank())
# Plot all Brazilian states
ggplot() +
geom_sf(data=state, fill="#2D3E50", color="#FEBF57", size=.15, show.legend = FALSE) +
labs(subtitle="States", size=8) +
theme_minimal() +
no_axis
# Download all municipalities of Rio
all_muni <- read_municipality( code_muni = "RJ", year= 2000)
# plot
ggplot() +
geom_sf(data=all_muni, fill="#2D3E50", color="#FEBF57", size=.15, show.legend = FALSE) +
labs(subtitle="Municipalities of Rio de Janeiro, 2000", size=8) +
theme_minimal() +
no_axis
# download Life Expectancy data
adh <- rio::import("http://atlasbrasil.org.br/2013/data/rawData/Indicadores%20Atlas%20-%20RADAR%20IDHM.xlsx", which = "Dados")
# keep only information for the year 2010 and the columns we want
adh <- subset(adh, ANO == 2014)
# Download the sf of all Brazilian states
all_states <- read_state(code_state= "all", year= 2014)
# joind the databases
all_states <-left_join(all_states, adh, by = c("abbrev_state" = "NOME_AGREGA"))
ggplot() +
geom_sf(data=all_states, aes(fill=ESPVIDA), color= NA, size=.15) +
labs(subtitle="Life Expectancy at birth, Brazilian States, 2014", size=8) +
scale_fill_distiller(palette = "Blues", name="Life Expectancy", limits = c(65,80)) +
theme_minimal() +
no_axis
# Get metadata with data addresses
metadata <- download_metadata()
# Open lookup table
temp_meta <- subset(metadata, geo == "lookup_muni")
# list paths of files to download
filesD <- as.character(temp_meta$download_path)
# download files
temps <- paste0(tempdir(),"/", unlist(lapply(strsplit(filesD,"/"),tail,n=1L)))
httr::GET(url=filesD, httr::progress(), httr::write_disk(temps, overwrite = T))
# read file
lookup_table_2010 <- utils::read.csv(temps, stringsAsFactors = F, encoding = 'UTF-8')
lookup_table_2010
lookup_table_2010$name_muni_format
lookup_table_2010
library(geobr)
??:::
?:::
# Get readme.md file
tempf <- file.path(tempdir(), "readme.md")
tempf
# check if metadata has already been downloaded
if (file.exists(tempf)) {
readme <- readLines(tempf, encoding = "UTF-8")
} else {
# download it and save to metadata
httr::GET(url="https://raw.githubusercontent.com/ipeaGIT/geobr/master/README.md", httr::write_disk(tempf, overwrite = T))
readme <- readLines(tempf, encoding = "UTF-8")
}
# find start and end of table
table_start <- grep("Available datasets:", readme) + 1
table_end <- grep("Other functions", readme) -1
# get table string in Markdown
table_strig <- readme[table_start:table_end]
table_strig
# read table as a data.frame
suppressWarnings({ df <- readr::read_delim(table_strig, delim = '|', trim_ws = T) })
df
?read.table
suppressWarnings({ df2 <- utils::read.table(table_strig, delim = '|', trim_ws = T) })
table_strig
suppressWarnings({ df2 <- utils::read.table(table_strig, sep = '|', trim_ws = T) })
suppressWarnings({ df2 <- utils::read.table(table_strig, sep = '|') })
df2 <- utils::read.table(table_strig, sep = '|')
head(table_strig)
utils::read.table(table_strig, sep = '|')
# read table as a data.frame
suppressWarnings({ df <- readr::read_delim(table_strig, delim = '|', trim_ws = T) })
# clean colunms
df$X1 <- NULL
df$X6 <- NULL
# remove 1st row with "-----"
df <- df[-1,]
# rename columns
colnames(df) <- c("function", "geography", "years", "source")
df
library(geobr)
