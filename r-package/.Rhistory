metadata <- utils::read.csv(tempf, stringsAsFactors=F)
metadata
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun='download_metadata', test_file("tests/testthat/test-download_metadata.R"))
metadata <- download_metadata(geography = 'amazonia_legal')
library(geobr)
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun='download_metadata', test_file("tests/testthat/test-download_metadata.R"))
function_coverage(fun='list_geobr', test_file("tests/testthat/test-list_geobr.R"))
function_coverage(fun='lookup_muni', test_file("tests/testthat/test-lookup_muni.R"))
system.time(  geobr_cov <- covr::package_coverage() )
geobr_cov
beepr::beep()
# download metadata
metadata <- download_metadata()
library(geobr)
# download metadata
metadata <- download_metadata()
metadata
head(metadata)
geography='amazon'
# Select geo
temp_meta <- subset(metadata, geo == geography)
temp_meta
geography='biomes'
geography
# Select geo
temp_meta <- subset(metadata, geo == geography)
temp_meta
year=2012
# Select year input
temp_meta <- select_year_input(temp_meta, y=year)
year=2019
# Select year input
temp_meta <- select_year_input(temp_meta, y=year)
library(geobr)
a <- read_amazon(year=2012)
}
a <- read_amazon(year=2012)
temp_meta <- select_metadata(geography="amazonia_legal", year=year, simplified=simplified)
year=2012
simplified=TRUE
showProgress=TRUE
# Get metadata with data url addresses
temp_meta <- select_metadata(geography="amazonia_legal", year=year, simplified=simplified)
# download metadata
metadata <- download_metadata()
geography="amazonia_legal"
year=year
simplified=simplified
# download metadata
metadata <- download_metadata()
metadata
# Select geo
temp_meta <- subset(metadata, geo == geography)
temp_meta
# Select year input
temp_meta <- select_year_input(temp_meta, y=year)
temp_meta
temp_meta <- select_data_type(temp_meta, simplified=simplified)
temp_meta
temp_meta
library(geobr)
a <- read_amazon(year=2012)
#' @family general area functions
#' @examples \donttest{
#'
#' library(geobr)
#'
#' # Read biomes
#'   b <- read_biomes(year=2019)
#'
#'}
#'
read_biomes <- function(year=2019, simplified=TRUE, showProgress=TRUE){
# Get metadata with data url addresses
temp_meta <- select_metadata(geography="biomes", year=year, simplified=simplified)
# Test year input
temp_meta <- test_year_input(temp_meta, y=year)
# list paths of files to download
file_url <- as.character(temp_meta$download_path)
# download files
temp_sf <- download_gpkg(file_url, progress_bar = showProgress)
return(temp_sf)
}
#' @family general area functions
#' @examples \donttest{
#'
#' library(geobr)
#'
#' # Read biomes
#'   b <- read_biomes(year=2019)
#'
#'}
#'
read_biomes <- function(year=2019, simplified=TRUE, showProgress=TRUE){
# Get metadata with data url addresses
temp_meta <- select_metadata(geography="biomes", year=year, simplified=simplified)
# list paths of files to download
file_url <- as.character(temp_meta$download_path)
# download files
temp_sf <- download_gpkg(file_url, progress_bar = showProgress)
return(temp_sf)
}
b <- read_biomes(year=2019)
library(geobr)
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun='read_biomes', test_file("tests/testthat/test-read_biomes.R"))
function_coverage(fun= 'read_amazon', test_file("tests/testthat/test-read_amazon.R"))
function_coverage(fun='read_census_tract', test_file("tests/testthat/test-read_census_tract.R"))
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun='download_metadata', test_file("tests/testthat/test-download_metadata.R"))
test_that("download_metadata", {
metadata <- download_metadata(geography = 'amazonia_legal')
testthat::expect_true(is(metadata, "data.frame"))
testthat::expect_equal(ncol(metadata), 5)
})
metadata <- download_metadata()
testthat::expect_true(is(metadata, "data.frame"))
testthat::expect_equal(ncol(metadata), 5)
testthat::expect_error( download_metadata( )  )
testthat::expect_error( download_metadata(data_type="asdasd") )
testthat::expect_error( download_metadata(geography = "aaa")  )
testthat::expect_error( download_metadata("asdasd") )
testthat::expect_error( download_metadata( NULL)  )
testthat::expect_error( download_metadata("asdasd") )
testthat::expect_error( download_metadata( NULL)  )
function_coverage(fun='download_metadata', test_file("tests/testthat/test-download_metadata.R"))
testthat::expect_output( download_metadata() )
download_metadata(
)
function_coverage(fun='download_metadata', test_file("tests/testthat/test-download_metadata.R"))
function_coverage(fun='list_geobr', test_file("tests/testthat/test-list_geobr.R"))
function_coverage(fun='lookup_muni', test_file("tests/testthat/test-lookup_muni.R"))
function_coverage(fun='grid_state_correspondence_table', test_file("tests/testthat/test-grid_state_correspondence_table.R"))
temp_meta <- select_metadata(geography="lookup_muni", year=NULL, simplified=F)
temp_meta <- select_metadata(geography="lookup_muni", year=2010, simplified=F)
temp_meta
function_coverage(fun='lookup_muni', test_file("tests/testthat/test-lookup_muni.R"))
function_coverage(fun='lookup_muni', test_file("tests/testthat/test-lookup_muni.R"))
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun='lookup_muni', test_file("tests/testthat/test-lookup_muni.R"))
function_coverage(fun='read_biomes', test_file("tests/testthat/test-read_biomes.R"))
function_coverage(fun='read_region', test_file("tests/testthat/test-read_region.R"))
function_coverage(fun= 'read_amazon', test_file("tests/testthat/test-read_amazon.R"))
function_coverage(fun= 'read_semiarid', test_file("tests/testthat/test-read_semiarid.R"))
function_coverage(fun= 'read_metro_area', test_file("tests/testthat/test-read_metro_area.R"))
function_coverage(fun= 'read_conservation_units', test_file("tests/testthat/test-read_conservation_units.R"))
test_that("read_conservation_units", {
# read data
test_sf <- read_conservation_units(date=201909)
testthat::expect_output(read_conservation_units())
# check sf object
testthat::expect_true(is(test_sf, "sf"))
# check projection
testthat::expect_equal(sf::st_crs(test_sf)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun= 'read_conservation_units', test_file("tests/testthat/test-read_conservation_units.R"))
function_coverage(fun='read_health_facilities', test_file("tests/testthat/test-read_health_facilities.R"))
# Get metadata with data url addresses
temp_meta <- select_metadata(geography="health_facilities", year=NULL, simplified=F)
# Get metadata with data url addresses
temp_meta <- select_metadata(geography="health_facilities", year=2015, simplified=F)
# list paths of files to download
file_url <- as.character(temp_meta$download_path)
file_url
function_coverage(fun='read_intermediate_region', test_file("tests/testthat/test-read_intermediate_region.R"))
function_coverage(fun='read_immediate_region', test_file("tests/testthat/test-read_immediate_region.R"))
function_coverage(fun='read_municipality', test_file("tests/testthat/test-read_municipality.R"))
function_coverage(fun='read_census_tract', test_file("tests/testthat/test-read_census_tract.R"))
function_coverage(fun='read_weighting_area', test_file("tests/testthat/test-read_weighting_area.R"))
# update Package coverage
Sys.setenv(NOT_CRAN = "true")
system.time(  geobr_cov <- covr::package_coverage() )
# update Package coverage
Sys.setenv(NOT_CRAN = "true")
system.time(  geobr_cov <- covr::package_coverage() )
geobr_cov
beepr::beep()
geobr_cov
grid_state_correspondence_table
function_coverage(fun='grid_state_correspondence_table', test_file("tests/testthat/test-grid_state_correspondence_table.R"))
data(grid_state_correspondence_table)
head(grid_state_correspondence_table)
expect_equal(ncol(grid_state_correspondence_table), 3)
expect_equal(nrow(grid_state_correspondence_table), 139)
test_that("grid_state_correspondence_table", {
# load data
#  load( system.file("data/grid_state_correspondence_table.RData", package="geobr") )
data(grid_state_correspondence_table)
head(grid_state_correspondence_table)
# test
expect_equal(ncol(grid_state_correspondence_table), 3)
expect_equal(nrow(grid_state_correspondence_table), 139)
})
context("grid_state_correspondence_table")
# skip tests because they take too much time
testthat::skip_on_cran()
test_that("grid_state_correspondence_table", {
# load data
#  load( system.file("data/grid_state_correspondence_table.RData", package="geobr") )
data(grid_state_correspondence_table)
head(grid_state_correspondence_table)
# test
expect_equal(ncol(grid_state_correspondence_table), 3)
expect_equal(nrow(grid_state_correspondence_table), 139)
})
function_coverage(fun='grid_state_correspondence_table', test_file("tests/testthat/test-grid_state_correspondence_table.R"))
Sys.setenv(NOT_CRAN = "false")
function_coverage(fun='read_urban_area', test_file("tests/testthat/test-read_urban_area.R"))
# Check package errors
Sys.setenv(NOT_CRAN = "false")
# Check package errors
Sys.setenv(NOT_CRAN = "false")
devtools::check(pkg = ".",  cran = TRUE)
library(geobr)
read_state()
testthat::expect_output( read_state() )
read_state(code_state=9999999, year=9999999)
expect_error(read_state(code_state=9999999, year=9999999))
# Wrong year and code
testthat::expect_error(read_state(code_state=9999999, year=9999999))
context("read_state")
# skip tests because they take too much time
testthat::skip_on_cran()
test_that("read_state", {
# read data
testthat::expect_output( read_state() )
testthat::expect_output( read_state(code_state=11, year=1991) )
testthat::expect_output( read_state(code_state="AC", year=2010) )
testthat::expect_output( read_state(code_state=11, year=2010) )
testthat::expect_output( read_state(code_state="all") )
test_code <- read_state(code_state=11, year=2010)
# check sf object
expect_true(is(test_code, "sf"))
# check number of weighting areas
expect_equal(nrow(test_code), 1)
# check projection
expect_equal(sf::st_crs(test_code)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
library(testthat)
test_that("read_state", {
# read data
testthat::expect_output( read_state() )
testthat::expect_output( read_state(code_state=11, year=1991) )
testthat::expect_output( read_state(code_state="AC", year=2010) )
testthat::expect_output( read_state(code_state=11, year=2010) )
testthat::expect_output( read_state(code_state="all") )
test_code <- read_state(code_state=11, year=2010)
# check sf object
testthat::expect_true(is(test_code, "sf"))
# check number of weighting areas
testthat::expect_equal(nrow(test_code), 1)
# check projection
testthat::expect_equal(sf::st_crs(test_code)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
# ERRORS
test_that("read_state", {
# Wrong year and code
testthat::expect_error(read_state(code_state=9999999, year=9999999))
# Wrong code
testthat::expect_error( read_state(code_state=NULL, year=1991) ) # EXception
testthat::expect_error(read_state(code_state=9999999))
testthat::expect_error(read_state(code_state=5201108312313213123123123))
testthat::expect_error(read_state(code_state="AC_ABCD"))
# Wrong year
testthat::expect_error(read_state( year=9999999))
})
library(covr)
library(testthat)
library(geobr)
Sys.setenv(NOT_CRAN = "true")
function_coverage(fun='read_state', test_file("tests/testthat/test-read_state.R"))
library(geobr)
a <- read_immediate_region()
a
b <- read_intermediate_region()
b
library(RCurl)
library(stringr)
library(sf)
library(janitor)
library(dplyr)
library(readr)
library(parallel)
library(data.table)
library(xlsx)
library(magrittr)
library(devtools)
library(lwgeom)
library(stringi)
# Root directory
root_dir <- "L:////# DIRUR #//ASMEQ//geobr//data-raw"
setwd(root_dir)
# Directory to keep raw zipped files
dir.create("./intermediate_regions")
setwd("./intermediate_regions")
# Create folders to save clean sf.rds files
destdir_clean <- "./shapes_in_sf_cleaned"
dir.create( destdir_clean , showWarnings = FALSE)
# read data
temp_sf <- st_read("RG2017_rgint.shp", quiet = F, stringsAsFactors=F, options = "ENCODING=UTF8")
temp_sf <- dplyr::rename(temp_sf, code_intermediate = rgint, name_intermediate = nome_rgint) %>%
dplyr::mutate(year = 2017,
# code_state
code_state = substr(code_intermediate,1,2),
# abbrev_state
abbrev_state =  ifelse(code_state== 11, "RO",
ifelse(code_state== 12, "AC",
ifelse(code_state== 13, "AM",
ifelse(code_state== 14, "RR",
ifelse(code_state== 15, "PA",
ifelse(code_state== 16, "AP",
ifelse(code_state== 17, "TO",
ifelse(code_state== 21, "MA",
ifelse(code_state== 22, "PI",
ifelse(code_state== 23, "CE",
ifelse(code_state== 24, "RN",
ifelse(code_state== 25, "PB",
ifelse(code_state== 26, "PE",
ifelse(code_state== 27, "AL",
ifelse(code_state== 28, "SE",
ifelse(code_state== 29, "BA",
ifelse(code_state== 31, "MG",
ifelse(code_state== 32, "ES",
ifelse(code_state== 33, "RJ",
ifelse(code_state== 35, "SP",
ifelse(code_state== 41, "PR",
ifelse(code_state== 42, "SC",
ifelse(code_state== 43, "RS",
ifelse(code_state== 50, "MS",
ifelse(code_state== 51, "MT",
ifelse(code_state== 52, "GO",
ifelse(code_state== 53, "DF",NA))))))))))))))))))))))))))),
# name_state
name_state =  ifelse(code_state== 11, "Rondônia",
ifelse(code_state== 12, "Acre",
ifelse(code_state== 13, "Amazônia",
ifelse(code_state== 14, "Roraima",
ifelse(code_state== 15, "Pará",
ifelse(code_state== 16, "Amapá",
ifelse(code_state== 17, "Tocantins",
ifelse(code_state== 21, "Maranhão",
ifelse(code_state== 22, "Piauí",
ifelse(code_state== 23, "Ceará",
ifelse(code_state== 24, "Rio Grande do Norte",
ifelse(code_state== 25, "Paraíba",
ifelse(code_state== 26, "Pernambuco",
ifelse(code_state== 27, "Alagoas",
ifelse(code_state== 28, "Sergipe",
ifelse(code_state== 29, "Bahia",
ifelse(code_state== 31, "Minas Gerais",
ifelse(code_state== 32, "Espírito Santo",
ifelse(code_state== 33, "Rio de Janeiro",
ifelse(code_state== 35, "São Paulo",
ifelse(code_state== 41, "Paraná",
ifelse(code_state== 42, "Santa Catarina",
ifelse(code_state== 43, "Rio Grande do Sul",
ifelse(code_state== 50, "Mato Grosso do Sul",
ifelse(code_state== 51, "Mato Grosso",
ifelse(code_state== 52, "Goiás",
ifelse(code_state== 53, "Distrito Federal",NA))))))))))))))))))))))))))),
# code_region
code_region = substr(code_intermediate,1,1),
# name_region
name_region = ifelse(code_region==1, 'Norte',
ifelse(code_region==2, 'Nordeste',
ifelse(code_region==3, 'Sudeste',
ifelse(code_region==4, 'Sul',
ifelse(code_region==5, 'Centro Oeste', NA))))))
# reorder columns
temp_sf <- dplyr::select(temp_sf, 'code_intermediate', 'name_intermediate','code_state', 'abbrev_state',
'name_state', 'code_region', 'name_region', 'geometry')
# Convert columns from factors to characters
temp_sf %>% dplyr::mutate_if(is.factor, as.character) -> temp_sf
# remove Z dimension of spatial data
temp_sf <- temp_sf %>% st_sf() %>% st_zm( drop = T, what = "ZM")
head(temp_sf)
# Make any invalid geometry valid # st_is_valid( sf)
temp_sf <- lwgeom::st_make_valid(temp_sf)
# Harmonize spatial projection CRS, using SIRGAS 2000 epsg (SRID): 4674
temp_sf <- if( is.na(st_crs(temp_sf)) ){ st_set_crs(temp_sf, 4674) } else { st_transform(temp_sf, 4674) }
st_crs(temp_sf) <- 4674
# keep code as.numeric()
temp_sf$code_state <- as.numeric(temp_sf$code_state)
# simplify
temp_sf_simplified <- st_transform(temp_sf, crs=3857) %>% sf::st_simplify(preserveTopology = T, dTolerance = 100) %>% st_transform(crs=4674)
# save original and simplified datasets
sf::st_write(temp_sf, paste0(destdir_clean, "/intermediate_regions_2017.gpkg") )
sf::st_write(temp_sf_simplified, paste0(destdir_clean, "/intermediate_regions_2017_simplified.gpkg") )
b <- read_intermediate_region()
b
mun2001 <- read_municipality(year=2001, code_muni = 'RJ')
i2 <- subset(mun2001, name_muni== 'Itaguaí')
i2
mun2001 <- read_municipality(year=2001, code_muni = 'RJ')
i2 <- subset(mun2001, name_muni== 'Itaguaí')
plot(i2)
head(mun2001)
mun2001 <- read_municipality(year=2001, code_muni = 'RJ')
i2 <- subset(mun2001, name_muni== 'Itaguaí')
i2
a <- read_municipality(year=1991)
a
a <- read_municipality(year=0000)
View(a)
b<- read_municipality(year=2000)
View(a)
a <- read_municipal_seat(year=1991)
a
a <- read_municipal_seat(year=0000)
a <- read_municipal_seat(year=2000)
a <- read_municipal_seat(year=2010)
a
a <- read_municipal_seat(year=1991)
a
a <- read_municipal_seat(year=1980)
a
library(geobr)
library(geobr)
a <- read_amazon(year=2012)
a <- read_amazon(year=2012, tp=1)
a <- read_amazon(year=2012, tp='a')
library(geobr)
rm(list = ls())
library(roxygen2)
library(devtools)
library(usethis)
library(testthat)
library(usethis)
# Check package errors
Sys.setenv(NOT_CRAN = "false")
devtools::check(pkg = ".",  cran = TRUE)
library(geobr)
library(sf)
library(dplyr)
library(rio)
# Available data sets
datasets <- list_geobr()
print(datasets, n=21)
# State of Sergige
state <- read_state(code_state="SE", year=2018)
state <- read_state(code_state="SE", year=2018)
mun <- read_municipality(code_muni="all", year=2018)
read_municipality <- function(code_muni="all", year=2010, simplified=TRUE, showProgress=TRUE, tp){
# deprecated 'tp' argument
if (!missing("tp")){stop(" 'tp' argument deprecated. Please use argument 'simplified' TRUE or FALSE")}
# Get metadata with data url addresses
temp_meta <- select_metadata(geography="municipality", year=year, simplified=simplified)
# BLOCK 2.1 From 1872 to 1991  ----------------------------
if( year < 1992){
# list paths of files to download
file_url <- as.character(temp_meta$download_path)
# download files
temp_sf <- download_gpkg(file_url, progress_bar = showProgress)
return(temp_sf)
} else {
# BLOCK 2.2 From 2000 onwards  ----------------------------
# 2.2 Verify code_muni Input
# if code_muni=="all", read the entire country
if(code_muni=="all"){ message("Loading data for the whole country. This might take a few minutes.\n")
# list paths of files to download
file_url <- as.character(temp_meta$download_path)
# download files
temp_sf <- download_gpkg(file_url, progress_bar = showProgress)
return(temp_sf)
}
else if( !(substr(x = code_muni, 1, 2) %in% temp_meta$code) & !(substr(x = code_muni, 1, 2) %in% temp_meta$code_abrev)){
stop("Error: Invalid Value to argument code_muni.")
} else{
# list paths of files to download
if (is.numeric(code_muni)){ file_url <- as.character(subset(temp_meta, code==substr(code_muni, 1, 2))$download_path) }
if (is.character(code_muni)){ file_url <- as.character(subset(temp_meta, code_abrev==substr(code_muni, 1, 2))$download_path) }
# download files
sf <- download_gpkg(file_url, progress_bar = showProgress)
# input is a state code
if(nchar(code_muni)==2){
return(sf) }
# input is a municipality code
else if(code_muni %in% sf$code_muni){
x <- code_muni
sf <- subset(sf, code_muni==x)
return(sf)
} else{
stop("Error: Invalid Value to argument code_muni.")
}
}
}
}
mun <- read_municipality(code_muni="all", year=2018)
}
library(geobr)
warnings()
