head(cc)
subset(a, name_muni == 'Anicuns' )
subset(a, name_muni == 'Adel√¢ndia' )
# download dos dados
m <- read_municipal_seat()
# Quantas vezes cada municipios se repete
freq <- table(m$code_muni)
freq
library(magrittr)
# Quantas vezes cada municipios se repete
freq <- table(m$code_muni) %>% as.data.frame( )
freq
head(freq)
# identifica repetidos
repetidos <- subset(freq, Freq >1 )
repetidos
# download dos dados
m <- read_municipal_seat(year=99999)
# download dos dados
m <- read_municipal_seat(year=1991)
# Quantas vezes cada municipios se repete
freq <- table(m$code_muni) %>% as.data.frame( )
# identifica repetidos
repetidos <- subset(freq, Freq >1 )
repetidos
# download dos dados
m <- read_municipal_seat(year=1872)
# Quantas vezes cada municipios se repete
freq <- table(m$code_muni) %>% as.data.frame( )
# identifica repetidos
repetidos <- subset(freq, Freq >1 )
repetidos
# download dos dados
m <- read_municipal_seat(year=1980)
# Quantas vezes cada municipios se repete
freq <- table(m$code_muni) %>% as.data.frame( )
# identifica repetidos
repetidos <- subset(freq, Freq >1 )
repetidos
Sys.getenv("TEST_ONE") == ""
devtools::check(pkg = ".",  cran = TRUE)
library(geobr)
a <- read_amazon()
plot(a)
a <- read_amazon(tp='original')
a <- read_amazon()
b <- read_amazon(tp='original')
head(a)
View(a)
View(b)
plot(a)
plot(b)
mapview::mapview(a) +b
meso <- read_meso_region(code_meso="all", year=2010)
plot(meso)
head(meso)
# Get metadata with data addresses
metadata <- download_metadata()
View(metadata)
temp_meta <- subset(metadata, geo=="meso_region")
View(temp_meta)
year=NULL
if (is.null(year)){ message("Using data from year 2010\n")
temp_meta <- subset(temp_meta, year==2010)
} else if (year %in% temp_meta$year){ temp_meta <- temp_meta[temp_meta[,2] == year, ]
} else { stop(paste0("Error: Invalid Value to argument 'year'. It must be one of the following: ",
paste(unique(temp_meta$year),collapse = " ")))
}
View(temp_meta)
tp="simplified"
temp_meta <- select_data_type(temp_meta, tp)
code_meso=33
meso <- read_meso_region(code_meso=12, year=2017)
plot(meso)
meso <- read_meso_region()
code_meso
tp
year
temp_meta$download_path
# read files and pile them up
files <- unlist(lapply(strsplit(filesD,"/"), tail, n = 1L))
# list paths of files to download
filesD <- as.character(temp_meta$download_path)
filesD
# if code_meso=="all", read the entire country
if(code_meso=="all"){ message("Loading data for the whole country\n")
# list paths of files to download
filesD <- as.character(temp_meta$download_path)
# input for progress bar
total <- length(filesD)
pb <- utils::txtProgressBar(min = 0, max = total, style = 3)
# download files
lapply(X=filesD, function(x){
i <- match(c(x),filesD)
httr::GET(url=x, #httr::progress(),
httr::write_disk(paste0(tempdir(),"/", unlist(lapply(strsplit(x,"/"),tail,n=1L))), overwrite = T))
utils::setTxtProgressBar(pb, i)
}
)
# closing progress bar
close(pb)
# read files and pile them up
files <- unlist(lapply(strsplit(filesD,"/"), tail, n = 1L))
files <- paste0(tempdir(),"/",files)
files <- lapply(X=files, FUN= sf::st_read, quiet=T)
shape <- do.call('rbind', files)
return(shape)
}
meso <- read_meso_region(code_meso = 5555555555555555)
meso <- read_meso_region(code_meso = "AC")
temp_meta
if (is.numeric(code_meso)){ filesD <- as.character(subset(temp_meta, code==substr(code_meso, 1, 2))$download_path) }
if (is.character(code_meso)){ filesD <- as.character(subset(temp_meta, code_abrev==substr(code_meso, 1, 2))$download_path) }
filesD
# download files
temps <- download_gpkg(filesD)
# read sf
shape <- sf::st_read(temps, quiet=T)
shape
im <- read_intermediate_region()
geobr_list()
library(geobr)
geobr_list()
a <- geobr::list_geobr()
a = geobr::list_geobr()
View(a)
rj <- read_state(code_state = 33)
sp <- read_state(code_state = 'SP')
plot(rj)
plot(sp)
a <- rbind(rj, sp)
plot(a)
m <- read_metro_area()
m <- read_metro_area(year==1111111)
m <- read_metro_area(year=1111111)
m <- read_metro_area(year=2013)
plot(m)
mapview::mapview(m)
m <- read_metro_area(year=2013, tp='original')
mapview::mapview(m)
geobr::list_geobr()
df <- data.frame(src = round(c(0x10000:0x10100,runif(100,
0x1000,0x100000))),
dst =
round(c(0x11000:0x11100,runif(100,0x1000,0x100000))))
hexlabels <- function(x)
sprintf("0x%s", as.character.hexmode(x))
ggplot(df, aes(x = src, y = dst)) +
geom_point() +
scale_x_continuous(labels = hexlabels) +
scale_y_continuous(labels = hexlabels)
library(ggplot2)
ggplot(df, aes(x = src, y = dst)) +
geom_point() +
scale_x_continuous(labels = hexlabels) +
scale_y_continuous(labels = hexlabels)
library(covr)
library(testthat)
library(geobr)
rm(list = ls())
library(roxygen2)
library(devtools)
library(usethis)
library(testthat)
library(usethis)
# Update documentation
devtools::document(pkg = ".")
# Check package errors
devtools::check(pkg = ".",  cran = TRUE)
system("R CMD build . --resave-data") # build tar.gz
library(covr)
library(testthat)
library(geobr)
# update Package coverage
Sys.setenv(NOT_CRAN = "true")
geobr_cov <- covr::package_coverage()
geobr_cov
?covr::codecov
?testthat
read_amazon(year=2012)
?fread
??fread
library(data.table)
?fread
# Get metadata with data addresses
metadata <- download_metadata()
# Select geo
temp_meta <- subset(metadata, geo=="state")
year=2010
tp="simplified"
# Verify year input
if (is.null(year)){ message("Using data from year 2010\n")
year <- 2010
temp_meta <- subset(temp_meta, year==2010)
} else if (year %in% temp_meta$year){ temp_meta <- temp_meta[temp_meta[,2] == year, ]
} else { stop(paste0("Error: Invalid Value to argument 'year'. It must be one of the following: ",
paste(unique(temp_meta$year),collapse = " ")))
}
filesD
temp_meta
code_state="SC"
# Verify year input
if (is.null(year)){ message("Using data from year 2010\n")
year <- 2010
temp_meta <- subset(temp_meta, year==2010)
} else if (year %in% temp_meta$year){ temp_meta <- temp_meta[temp_meta[,2] == year, ]
} else { stop(paste0("Error: Invalid Value to argument 'year'. It must be one of the following: ",
paste(unique(temp_meta$year),collapse = " ")))
}
# if code_state=="all", read the entire country
if(code_state=="all"){ message("Loading data for the whole country\n")
# list paths of files to download
filesD <- as.character(temp_meta$download_path)
# input for progress bar
total <- length(filesD)
pb <- utils::txtProgressBar(min = 0, max = total, style = 3)
# download files
lapply(X=filesD, function(x){
i <- match(c(x),filesD)
httr::GET(url=x, #httr::progress(),
httr::write_disk(paste0(tempdir(),"/", unlist(lapply(strsplit(x,"/"),tail,n=1L))), overwrite = T))
utils::setTxtProgressBar(pb, i)
}
)
# closing progress bar
close(pb)
# read files and pile them up
files <- unlist(lapply(strsplit(filesD,"/"), tail, n = 1L))
files <- paste0(tempdir(),"/",files)
files <- lapply(X=files, FUN= sf::st_read, quiet=T)
shape <- do.call('rbind', files)
return(shape)
}
if( !(substr(x = code_state, 1, 2) %in% temp_meta$code) & !(substr(x = code_state, 1, 2) %in% temp_meta$code_abrev)){
stop("Error: Invalid Value to argument code_state.")
} else{
# list paths of files to download
if (is.numeric(code_state)){ filesD <- as.character(subset(temp_meta, code==substr(code_state, 1, 2))$download_path) }
if (is.character(code_state)){ filesD <- as.character(subset(temp_meta, code_abrev==substr(code_state, 1, 2))$download_path) }
# download files
temps <- download_gpkg(filesD)
# read sf
shape <- sf::st_read(temps, quiet=T)
if(nchar(code_state)==2){
return(shape)
# } else if(code_state %in% shape$code_state){
#   x <- code_state
#   shape <- subset(shape, code_state==x)
#   return(shape)
} else{
stop("Error: Invalid Value to argument code_state.")
}
}
filesD
filesD <- filesD[2]
filesD
temps <- paste0(tempdir(),"/", unlist(lapply(strsplit(filesD,"/"),tail,n=1L)))
httr::GET(url=filesD, httr::progress(), httr::write_disk(temps, overwrite = T))
2+2
httr::GET(url=filesD, httr::progress(), httr::write_disk(temps, overwrite = T))
x <- GET("http://httpbin.org/bytes/102400", progress(), cap_speed)
library(httr)
x <- GET("http://httpbin.org/bytes/102400", progress(), cap_speed)
cap_speed <- config(max_recv_speed_large = 10000)
x <- GET("http://httpbin.org/bytes/102400", progress(), cap_speed)
x <- GET("http://httpbin.org/stream-bytes/102400", progress(), cap_speed)
system.time(  geobr_cov <- covr::package_coverage() )
# ERRORS and messagens  -----------------------
test_that("read_biomes", {
# skip tests because they take too much time
skip_on_cran()
# skip_on_travis()
# Wrong year
expect_error(read_biomes(year=9999999))
expect_error(read_biomes(year="xxx"))
})
test_that("read_biomes", {
# skip tests because they take too much time
skip_on_cran()
# skip_on_travis()
# read data
expect_message(read_biomes(year=NULL))
test_sf <- read_biomes(year=2004)
# check sf object
expect_true(is(test_sf, "sf"))
# check number of micro
expect_equal(test_sf$code_biome %>% length(), 10)
# check projection
#  expect_equal(sf::st_crs(test_sf)[[2]], "+proj=longlat +ellps=GRS80 +no_defs")
})
test_sf <- read_biomes(year=2004)
sf::st_crs(test_sf)
expect_equal(sf::st_crs(test_sf)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
test_that("read_census_tract", {
# read data
test_code_2000 <- read_census_tract(code_tract = 1100023, year = 2000)
test_code_2010 <- read_census_tract(code_tract = 1100023, year = 2010)
test_code2_2010 <- read_census_tract(code_tract = 1100023, year = NULL)
test_zone_2000 <- read_census_tract(code_tract = "AC", zone = "rural", year=2000)
test_zone_2010 <- read_census_tract(code_tract = "AC", zone = "rural", year=2010)
test_zone2_2010 <- read_census_tract(code_tract = "AP", zone = "rural", year=NULL)
test_state_code_2000 <- read_census_tract(code_tract = 11, year = 2000)
test_state_code_2010 <- read_census_tract(code_tract = 11, year = 2010)
test_state_code2_2010 <- read_census_tract(code_tract = 11, year = NULL)
test_all_2000 <- read_census_tract(code_tract = 'all', year = 2000)
test_all_2010 <- read_census_tract(code_tract = 'all', year = 2010)
test_all2_2010 <- read_census_tract(code_tract = 'all', year = NULL)
# check sf object
expect_true(is(test_code_2000, "sf"))
expect_true(is(test_code_2010, "sf"))
expect_true(is(test_code2_2010, "sf"))
expect_true(is(test_zone_2000, "sf"))
expect_true(is(test_zone_2010, "sf"))
expect_true(is(test_zone2_2010, "sf"))
expect_true(is(test_state_code_2000, "sf"))
expect_true(is(test_state_code_2010, "sf"))
expect_true(is(test_state_code2_2010, "sf"))
expect_true(is(test_all_2000, "sf"))
expect_true(is(test_all_2010, "sf"))
expect_true(is(test_all2_2010, "sf"))
# check projection
expect_equal(sf::st_crs(test_code_2010)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
expect_equal(sf::st_crs(test_code_2000)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
test_that("read_census_tract", {
# read data
test_code_2000 <- read_census_tract(code_tract = 1100023, year = 2000)
test_code2_2010 <- read_census_tract(code_tract = 1100023, year = NULL)
test_zone_2000 <- read_census_tract(code_tract = "AC", zone = "rural", year=2000)
test_zone2_2010 <- read_census_tract(code_tract = "AP", zone = "rural", year=NULL)
test_state_code_2000 <- read_census_tract(code_tract = 11, year = 2000)
test_state_code2_2010 <- read_census_tract(code_tract = 11, year = NULL)
test_all_2000 <- read_census_tract(code_tract = 'all', year = 2000)
test_all2_2010 <- read_census_tract(code_tract = 'all', year = NULL)
# check sf object
expect_true(is(test_code_2000, "sf"))
expect_true(is(test_code_2010, "sf"))
expect_true(is(test_code2_2010, "sf"))
expect_true(is(test_zone_2000, "sf"))
expect_true(is(test_zone_2010, "sf"))
expect_true(is(test_zone2_2010, "sf"))
expect_true(is(test_state_code_2000, "sf"))
expect_true(is(test_state_code_2010, "sf"))
expect_true(is(test_state_code2_2010, "sf"))
expect_true(is(test_all_2000, "sf"))
expect_true(is(test_all_2010, "sf"))
expect_true(is(test_all2_2010, "sf"))
# check projection
expect_equal(sf::st_crs(test_code_2010)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
expect_equal(sf::st_crs(test_code_2000)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
test_that("read_census_tract", {
# read data
test_code_2000 <- read_census_tract(code_tract = 1100023, year = 2000)
test_code2_2010 <- read_census_tract(code_tract = 1100023, year = NULL)
test_zone_2000 <- read_census_tract(code_tract = "AC", zone = "rural", year=2000)
test_zone2_2010 <- read_census_tract(code_tract = "AP", zone = "rural", year=NULL)
test_state_code_2000 <- read_census_tract(code_tract = 11, year = 2000)
test_state_code2_2010 <- read_census_tract(code_tract = 11, year = NULL)
test_all_2000 <- read_census_tract(code_tract = 'all', year = 2000)
test_all2_2010 <- read_census_tract(code_tract = 'all', year = NULL)
# check sf object
expect_true(is(test_code_2000, "sf"))
expect_true(is(test_code2_2010, "sf"))
expect_true(is(test_zone_2000, "sf"))
expect_true(is(test_zone2_2010, "sf"))
expect_true(is(test_state_code_2000, "sf"))
expect_true(is(test_state_code2_2010, "sf"))
expect_true(is(test_all_2000, "sf"))
expect_true(is(test_all2_2010, "sf"))
# check projection
expect_equal(sf::st_crs(test_code_2010)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
expect_equal(sf::st_crs(test_code_2000)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
test_that("read_census_tract", {
# read data
test_code_2000 <- read_census_tract(code_tract = 1100023, year = 2000)
test_code2_2010 <- read_census_tract(code_tract = 1100023, year = NULL)
test_zone_2000 <- read_census_tract(code_tract = "AC", zone = "rural", year=2000)
test_zone2_2010 <- read_census_tract(code_tract = "AP", zone = "rural", year=NULL)
test_state_code_2000 <- read_census_tract(code_tract = 11, year = 2000)
test_state_code2_2010 <- read_census_tract(code_tract = 11, year = NULL)
test_all_2000 <- read_census_tract(code_tract = 'all', year = 2000)
test_all2_2010 <- read_census_tract(code_tract = 'all', year = NULL)
# check sf object
expect_true(is(test_code_2000, "sf"))
expect_true(is(test_code2_2010, "sf"))
expect_true(is(test_zone_2000, "sf"))
expect_true(is(test_zone2_2010, "sf"))
expect_true(is(test_state_code_2000, "sf"))
expect_true(is(test_state_code2_2010, "sf"))
expect_true(is(test_all_2000, "sf"))
expect_true(is(test_all2_2010, "sf"))
# check projection
expect_equal(sf::st_crs(test_code_2000)[[2]], "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
})
Sys.setenv(NOT_CRAN = "false")
system.time(  devtools::test(pkg = ".",  cran = TRUE) )
Sys.setenv(NOT_CRAN = "false")
system.time(  devtools::test(pkg = ".",  cran = TRUE) )
Sys.setenv(NOT_CRAN = "true")
system.time(  devtools::test(pkg = ".",  cran = TRUE) )
beepr::beep()
Sys.setenv(NOT_CRAN = "false")
system.time(  devtools::test(pkg = ".",  cran = TRUE) )
beepr::beep()
Sys.setenv(NOT_CRAN = "true")
system.time(  devtools::test(pkg = ".",  cran = TRUE) )
beepr::beep()
Sys.setenv(NOT_CRAN = "false")
system.time(  devtools::test(pkg = ".",  cran = TRUE) )
beepr::beep()
update <- 2012
library(RCurl)
library(stringr)
library(sf)
library(dplyr)
library(readr)
library(data.table)
library(magrittr)
library(lwgeom)
library(stringi)
###### 0. Create Root folder to save the data -----------------
# Root directory
root_dir <- "L:\\# DIRUR #\\ASMEQ\\geobr\\data-raw"
setwd(root_dir)
# Directory to keep raw zipped files
dir.create("./amazonia_legal")
destdir_raw <- paste0("./amazonia_legal/",update)
dir.create(destdir_raw)
#### 2. Unzipe shape files -----------------
setwd(destdir_raw)
# read data
temp_sf <- st_read("./amazonia_legal.shp", quiet = F, stringsAsFactors=F)
###### 0. Create Root folder to save the data -----------------
# Root directory
root_dir <- "L:\\# DIRUR #\\ASMEQ\\geobr\\data-raw"
setwd(root_dir)
# Directory to keep raw zipped files
dir.create("./amazonia_legal")
destdir_raw <- paste0("./amazonia_legal/",update)
dir.create(destdir_raw)
# Create folders to save clean sf.rds files  -----------------
dir.create("./amazonia_legal/shapes_in_sf_cleaned", showWarnings = FALSE)
destdir_clean <- paste0("./amazonia_legal/shapes_in_sf_cleaned/",update)
dir.create(destdir_clean)
#### 2. Unzipe shape files -----------------
setwd(destdir_raw)
# read data
temp_sf <- st_read("./amazonia_legal.shp", quiet = F, stringsAsFactors=F)
#### 0. Download original data sets from source website -----------------
# Download and read into CSV at the same time
ftp_shp <- 'http://mapas.mma.gov.br/ms_tmp/amazonia_legal.shp'
ftp_shx <- 'http://mapas.mma.gov.br/ms_tmp/amazonia_legal.shx'
ftp_dbf <- 'http://mapas.mma.gov.br/ms_tmp/amazonia_legal.dbf'
ftp <- c(ftp_shp,ftp_shx,ftp_dbf)
aux_ft <- c("shp","shx","dbf")
for(i in 1:length(ftp)){
download.file(url = ftp[i],
destfile = paste0(destdir_raw,"/","amazonia_legal.",aux_ft[i]) )
}
library(RCurl)
library(tidyverse)
library(stringr)
library(sf)
library(magrittr)
library(data.table)
library(parallel)
library(lwgeom)
library(geobr)
library(mapview)
# Root directory
root_dir <- "L:////# DIRUR #//ASMEQ//geobr//data-raw"
setwd(root_dir)
head_dir <- "L:////# DIRUR #//ASMEQ//geobr//data-raw//municipal_seat"
# head_dir <- "C:/Users/rafa/Desktop/data/municipal_seat"
dir.create(head_dir)
########  1. Unzip original data sets downloaded from IBGE -----------------
setwd(head_dir)
# List all zip files for all years
all_zipped_files <- list.files(full.names = T, recursive = T, pattern = ".zip")
add_state_abbrev <- function(temp_sf){
temp_sf <- temp_sf %>% mutate(abbrev_state =  ifelse(code_state== 11, "RO",
ifelse(code_state== 12, "AC",
ifelse(code_state== 13, "AM",
ifelse(code_state== 14, "RR",
ifelse(code_state== 15, "PA",
ifelse(code_state== 16, "AP",
ifelse(code_state== 17, "TO",
ifelse(code_state== 21, "MA",
ifelse(code_state== 22, "PI",
ifelse(code_state== 23, "CE",
ifelse(code_state== 24, "RN",
ifelse(code_state== 25, "PB",
ifelse(code_state== 26, "PE",
ifelse(code_state== 27, "AL",
ifelse(code_state== 28, "SE",
ifelse(code_state== 29, "BA",
ifelse(code_state== 31, "MG",
ifelse(code_state== 32, "ES",
ifelse(code_state== 33, "RJ",
ifelse(code_state== 35, "SP",
ifelse(code_state== 41, "PR",
ifelse(code_state== 42, "SC",
ifelse(code_state== 43, "RS",
ifelse(code_state== 50, "MS",
ifelse(code_state== 51, "MT",
ifelse(code_state== 52, "GO",
ifelse(code_state== 53, "DF",NA))))))))))))))))))))))))))))
return(temp_sf)
}
temp_sf$code_muni
