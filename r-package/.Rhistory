# fix row names
rownames(temp_sf) <- 1:nrow(temp_sf)
# Add state and region information
#temp_sf <- add_region_info(temp_sf, column='code_health_region')
temp_sf <- add_state_info(temp_sf, column='code_health_region')
# reorder columns
temp_sf <- dplyr::select(temp_sf,
"code_health_region", "name_health_region",
"code_state", "abbrev_state", "name_state", 'geometry')
# 4. every string column with UTF-8 encoding -----------------
# convert all factor columns to character
temp_sf <- use_encoding_utf8(temp_sf)
###### Harmonize spatial projection -----------------
# Harmonize spatial projection CRS, using SIRGAS 2000 epsg (SRID): 4674
temp_sf <- harmonize_projection(temp_sf)
st_crs(temp_sf)
###### 5. remove Z dimension of spatial data-----------------
temp_sf <- temp_sf %>% st_sf() %>% st_zm( drop = T, what = "ZM")
head(temp_sf)
###### 6. fix eventual topology issues in the data-----------------
temp_sf <- sf::st_make_valid(temp_sf)
###### convert to MULTIPOLYGON -----------------
temp_sf <- to_multipolygon(temp_sf)
###### 7. generate a lighter version of the dataset with simplified borders -----------------
# skip this step if the dataset is made of points, regular spatial grids or rater data
# simplify
temp_sf_simplified <- st_transform(temp_sf, crs=3857) %>%
sf::st_simplify(preserveTopology = T, dTolerance = 100) %>% st_transform(crs=4674)
###### 8. Clean data set and save it -----------------
# save original and simplified datasets
sf::st_write(temp_sf,  paste0("./shapes_in_sf_cleaned/", year,"/", state,".gpkg") )
sf::st_write(temp_sf_simplified,paste0("./shapes_in_sf_cleaned/", year,"/", state,"_simplified.gpkg") )
}
# list address of original files
map_files <- list.files('./raw_data', pattern = '_regsaud.MAP', full.names = T, recursive = T)
# list address of original files
map_files <- list.files('./raw_data', pattern = '_regsaud.MAP', full.names = T, recursive = T)
map_files
map_files
map_files <- map_files[ substr(map_files, 31,31) != "_" ]
map_files
prep_map <- function(i){ # i <- map_files[1]
# get year and state
year <- substr(i, 24,27)
state <- substr(i, 29,30) %>% toupper()
# part1 - get names of regions --------------------------------------
mp <- basic_read_map( i )
name_health_region <- attr(mp,"region.name")
code_health_region <- attr(mp,"region.id")
# part2 - get regions as sf objects ---------------------------------
o <- maptools:::readMAP2polylist( i )
oo <- maptools:::.makePolylistValid(o)
ooo <- maptools:::.polylist2SpP(oo, tol=.Machine$double.eps^(1/4))
#rn <- row.names(ooo)
df <- data.frame(code_health_region=code_health_region, row.names=code_health_region, name_health_region=name_health_region, stringsAsFactors=FALSE)
res <- SpatialPolygonsDataFrame(ooo, data=df)
# fix “orphaned hole” in a polygon
slot(res, "polygons") <- lapply(slot(res, "polygons"), checkPolygonsHoles)
# convert to sf
temp_sf <- st_as_sf(res)
# plot(temp_sf)
# fix row names
rownames(temp_sf) <- 1:nrow(temp_sf)
# Add state and region information
#temp_sf <- add_region_info(temp_sf, column='code_health_region')
temp_sf <- add_state_info(temp_sf, column='code_health_region')
# reorder columns
temp_sf <- dplyr::select(temp_sf,
"code_health_region", "name_health_region",
"code_state", "abbrev_state", "name_state", 'geometry')
# 4. every string column with UTF-8 encoding -----------------
# convert all factor columns to character
temp_sf <- use_encoding_utf8(temp_sf)
###### Harmonize spatial projection -----------------
# Harmonize spatial projection CRS, using SIRGAS 2000 epsg (SRID): 4674
temp_sf <- harmonize_projection(temp_sf)
st_crs(temp_sf)
###### 5. remove Z dimension of spatial data-----------------
temp_sf <- temp_sf %>% st_sf() %>% st_zm( drop = T, what = "ZM")
head(temp_sf)
###### 6. fix eventual topology issues in the data-----------------
temp_sf <- sf::st_make_valid(temp_sf)
###### convert to MULTIPOLYGON -----------------
temp_sf <- to_multipolygon(temp_sf)
###### 7. generate a lighter version of the dataset with simplified borders -----------------
# skip this step if the dataset is made of points, regular spatial grids or rater data
# simplify
temp_sf_simplified <- st_transform(temp_sf, crs=3857) %>%
sf::st_simplify(preserveTopology = T, dTolerance = 100) %>% st_transform(crs=4674)
###### 8. Clean data set and save it -----------------
# save original and simplified datasets
sf::st_write(temp_sf,  paste0("./shapes_in_sf_cleaned/", year,"/", state,".gpkg") )
sf::st_write(temp_sf_simplified,paste0("./shapes_in_sf_cleaned/", year,"/", state,"_simplified.gpkg") )
}
# Parallel processing using future.apply
future::plan(future::multiprocess)
map_files
paste0('working on', i)
##### START prep function ------------------------
prep_map <- function(i){ # i <- map_files[1]
message(paste0('working on', i))
# get year and state
year <- substr(i, 24,27)
state <- substr(i, 29,30) %>% toupper()
# part1 - get names of regions --------------------------------------
mp <- basic_read_map( i )
name_health_region <- attr(mp,"region.name")
code_health_region <- attr(mp,"region.id")
# part2 - get regions as sf objects ---------------------------------
o <- maptools:::readMAP2polylist( i )
oo <- maptools:::.makePolylistValid(o)
ooo <- maptools:::.polylist2SpP(oo, tol=.Machine$double.eps^(1/4))
#rn <- row.names(ooo)
df <- data.frame(code_health_region=code_health_region, row.names=code_health_region, name_health_region=name_health_region, stringsAsFactors=FALSE)
res <- SpatialPolygonsDataFrame(ooo, data=df)
# fix “orphaned hole” in a polygon
slot(res, "polygons") <- lapply(slot(res, "polygons"), checkPolygonsHoles)
# convert to sf
temp_sf <- st_as_sf(res)
# plot(temp_sf)
# fix row names
rownames(temp_sf) <- 1:nrow(temp_sf)
# Add state and region information
#temp_sf <- add_region_info(temp_sf, column='code_health_region')
temp_sf <- add_state_info(temp_sf, column='code_health_region')
# reorder columns
temp_sf <- dplyr::select(temp_sf,
"code_health_region", "name_health_region",
"code_state", "abbrev_state", "name_state", 'geometry')
# 4. every string column with UTF-8 encoding -----------------
# convert all factor columns to character
temp_sf <- use_encoding_utf8(temp_sf)
###### Harmonize spatial projection -----------------
# Harmonize spatial projection CRS, using SIRGAS 2000 epsg (SRID): 4674
temp_sf <- harmonize_projection(temp_sf)
st_crs(temp_sf)
###### 5. remove Z dimension of spatial data-----------------
temp_sf <- temp_sf %>% st_sf() %>% st_zm( drop = T, what = "ZM")
head(temp_sf)
###### 6. fix eventual topology issues in the data-----------------
temp_sf <- sf::st_make_valid(temp_sf)
###### convert to MULTIPOLYGON -----------------
temp_sf <- to_multipolygon(temp_sf)
###### 7. generate a lighter version of the dataset with simplified borders -----------------
# skip this step if the dataset is made of points, regular spatial grids or rater data
# simplify
temp_sf_simplified <- st_transform(temp_sf, crs=3857) %>%
sf::st_simplify(preserveTopology = T, dTolerance = 100) %>% st_transform(crs=4674)
###### 8. Clean data set and save it -----------------
# save original and simplified datasets
sf::st_write(temp_sf,  paste0("./shapes_in_sf_cleaned/", year,"/", state,".gpkg") )
sf::st_write(temp_sf_simplified,paste0("./shapes_in_sf_cleaned/", year,"/", state,"_simplified.gpkg") )
}
pbapply::pblapply(map_files, prep_map)
map_files
# regioes de cada estado
map_files <- map_files[ substr(map_files, 31,31) == "_" ]
# Parallel processing using future.apply
future::plan(future::multiprocess)
pbapply::pblapply(map_files, prep_map)
map_files
# list address of original files
map_files <- list.files('./raw_data', pattern = '_regsaud.MAP', full.names = T, recursive = T)
# regioes de cada estado
map_files <- map_files[ substr(map_files, 31,31) == "_" ]
pbapply::pblapply(map_files, prep_map)
# list address of original files
map_files <- list.files('./raw_data', pattern = 'br_regsaud.MAP', full.names = T, recursive = T)
map_files
map_files
# original data source
ftp://ftp.datasus.gov.br/territorio/mapas/
####### Load Support functions to use in the preprocessing of the data -----------------
source("./prep_data/prep_functions.R")
# Root directory
root_dir <- "L:////# DIRUR #//ASMEQ//geobr//data-raw"
setwd(root_dir)
# Directory to save clean files
dir.create("./health_regions")
setwd("./health_regions")
# Directory to keep raw zipped files
dir.create("./raw_data")
# Directory to save clean files
dir.create("./shapes_in_sf_cleaned")
# Create folders to save clean files
years_available <- c(1991, 1994, 1997, 2001, 2005, 2013)
lapply(X=years_available, FUN= function(i){
destdir_clean <- paste0("./shapes_in_sf_cleaned/",i)
dir.create( destdir_clean , showWarnings = FALSE)}
)
zip_files <- list.files('./raw_data', pattern = '.zip', full.names = T)
## read function to get names in correct encoding
# source: https://repositorio.ufrn.br/jspui/bitstream/123456789/17008/1/DanielMC_DISSERT.pdf
basic_read_map = function(filename){
zz=file(filename,"rb")
#
# header of .map
#
versao = readBin(zz,"integer",1,size=2)  # 100 = versao 1.00
#Bounding Box
Leste = readBin(zz,"numeric",1,size=4)
Norte = readBin(zz,"numeric",1,size=4)
Oeste = readBin(zz,"numeric",1,size=4)
Sul   = readBin(zz,"numeric",1,size=4)
geocodigo = ""
nome = ""
xleg = 0
yleg = 0
sede = FALSE
poli = list()
i = 0
#
# repeat of each object in file
#
repeat{
tipoobj = readBin(zz,"integer",1,size=1) # 0=Poligono, 1=PoligonoComSede, 2=Linha, 3=Ponto
if (length(tipoobj) == 0) break
i = i + 1
Len = readBin(zz,"integer",1,size=1)  # length byte da string Pascal
geocodigo[i] = readChar(zz,10)
Len = readBin(zz,"integer",1,size=1)  # length byte da string Pascal
nome[i] = substr(readChar(zz,25),1,Len)
xleg[i] = readBin(zz,"numeric",1,size=4)
yleg[i] = readBin(zz,"numeric",1,size=4)
numpontos = readBin(zz,"integer",1,size=2)
sede = sede || (tipoobj = 1)
x=0
y=0
for (j in 1:numpontos){
x[j] = readBin(zz,"numeric",1,size=4)
y[j] = readBin(zz,"numeric",1,size=4)
}
# separate polygons
xInic = x[1]
yInic = y[1]
for (j in 2:numpontos){
if (x[j] == xInic & y[j] == yInic) {x[j]=NA; y[j] = NA}
}
poli[[i]] = c(x,y)
dim(poli[[i]]) = c(numpontos,2)
}
class(poli) = "polylist"
attr(poli,"region.id") = geocodigo
attr(poli,"region.name") = nome
attr(poli,"centroid") = list(x=xleg,y=yleg)
attr(poli,"sede") = sede
attr(poli,"maplim") = list(x=c(Oeste,Leste),y=c(Sul,Norte))
close(zz)
return(poli)
}
##### START prep function ------------------------
prep_map <- function(i){ # i <- map_files[1]
message(paste0('working on', i))
# get year and state
year <- substr(i, 24,27)
state <- substr(i, 29,30) %>% toupper()
# part1 - get names of regions --------------------------------------
mp <- basic_read_map( i )
name_health_region <- attr(mp,"region.name")
code_health_region <- attr(mp,"region.id")
# part2 - get regions as sf objects ---------------------------------
o <- maptools:::readMAP2polylist( i )
oo <- maptools:::.makePolylistValid(o)
ooo <- maptools:::.polylist2SpP(oo, tol=.Machine$double.eps^(1/4))
#rn <- row.names(ooo)
df <- data.frame(code_health_region=code_health_region, row.names=code_health_region, name_health_region=name_health_region, stringsAsFactors=FALSE)
res <- SpatialPolygonsDataFrame(ooo, data=df)
# fix “orphaned hole” in a polygon
slot(res, "polygons") <- lapply(slot(res, "polygons"), checkPolygonsHoles)
# convert to sf
temp_sf <- st_as_sf(res)
# plot(temp_sf)
# fix row names
rownames(temp_sf) <- 1:nrow(temp_sf)
# Add state and region information
#temp_sf <- add_region_info(temp_sf, column='code_health_region')
temp_sf <- add_state_info(temp_sf, column='code_health_region')
# reorder columns
temp_sf <- dplyr::select(temp_sf,
"code_health_region", "name_health_region",
"code_state", "abbrev_state", "name_state", 'geometry')
# 4. every string column with UTF-8 encoding -----------------
# convert all factor columns to character
temp_sf <- use_encoding_utf8(temp_sf)
###### Harmonize spatial projection -----------------
# Harmonize spatial projection CRS, using SIRGAS 2000 epsg (SRID): 4674
temp_sf <- harmonize_projection(temp_sf)
st_crs(temp_sf)
###### 5. remove Z dimension of spatial data-----------------
temp_sf <- temp_sf %>% st_sf() %>% st_zm( drop = T, what = "ZM")
head(temp_sf)
###### 6. fix eventual topology issues in the data-----------------
temp_sf <- sf::st_make_valid(temp_sf)
###### convert to MULTIPOLYGON -----------------
temp_sf <- to_multipolygon(temp_sf)
###### 7. generate a lighter version of the dataset with simplified borders -----------------
# skip this step if the dataset is made of points, regular spatial grids or rater data
# simplify
temp_sf_simplified <- st_transform(temp_sf, crs=3857) %>%
sf::st_simplify(preserveTopology = T, dTolerance = 100) %>% st_transform(crs=4674)
###### 8. Clean data set and save it -----------------
# save original and simplified datasets
sf::st_write(temp_sf,  paste0("./shapes_in_sf_cleaned/", year,"/", state,".gpkg") )
sf::st_write(temp_sf_simplified,paste0("./shapes_in_sf_cleaned/", year,"/", state,"_simplified.gpkg") )
}
# list address of original files
map_files <- list.files('./raw_data', pattern = 'br_regsaud.MAP', full.names = T, recursive = T)
map_files
i <- map_files[6]
i
message(paste0('working on', i))
# get year and state
year <- substr(i, 24,27)
state <- substr(i, 29,30) %>% toupper()
library(sf)
library(dplyr)
library(tidyverse)
library(tidyr)
library(data.table)
library(mapview)
library(readr)
library(maptools)
# https://stackoverflow.com/questions/61614314/how-to-read-a-map-file-extension-in-r
#> Metadata:
# get year and state
year <- substr(i, 24,27)
state <- substr(i, 29,30) %>% toupper()
state
# part1 - get names of regions --------------------------------------
mp <- basic_read_map( i )
name_health_region <- attr(mp,"region.name")
code_health_region <- attr(mp,"region.id")
# part2 - get regions as sf objects ---------------------------------
o <- maptools:::readMAP2polylist( i )
oo <- maptools:::.makePolylistValid(o)
ooo <- maptools:::.polylist2SpP(oo, tol=.Machine$double.eps^(1/4))
oo
ooo <- maptools:::.polylist2SpP(oo, tol=.Machine$double.eps^(1/4))
##### START prep function ------------------------
prep_map <- function(i){ # i <- map_files[6]
message(paste0('working on', i))
# get year and state
year <- substr(i, 24,27)
state <- substr(i, 29,30) %>% toupper()
# part1 - get names of regions --------------------------------------
mp <- basic_read_map( i )
name_health_region <- attr(mp,"region.name")
code_health_region <- attr(mp,"region.id")
# part2 - get regions as sf objects ---------------------------------
o <- maptools:::readMAP2polylist( i )
oo <- maptools:::.makePolylistValid(o)
ooo <- maptools:::.polylist2SpP(oo, tol=.Machine$double.eps^(1/4))
#rn <- row.names(ooo)
df <- data.frame(code_health_region=code_health_region, row.names=code_health_region, name_health_region=name_health_region, stringsAsFactors=FALSE)
res <- SpatialPolygonsDataFrame(ooo, data=df)
# fix “orphaned hole” in a polygon
slot(res, "polygons") <- lapply(slot(res, "polygons"), checkPolygonsHoles)
# convert to sf
temp_sf <- st_as_sf(res)
# plot(temp_sf)
# fix row names
rownames(temp_sf) <- 1:nrow(temp_sf)
# Add state and region information
#temp_sf <- add_region_info(temp_sf, column='code_health_region')
temp_sf <- add_state_info(temp_sf, column='code_health_region')
# reorder columns
temp_sf <- dplyr::select(temp_sf,
"code_health_region", "name_health_region",
"code_state", "abbrev_state", "name_state", 'geometry')
# 4. every string column with UTF-8 encoding -----------------
# convert all factor columns to character
temp_sf <- use_encoding_utf8(temp_sf)
###### Harmonize spatial projection -----------------
# Harmonize spatial projection CRS, using SIRGAS 2000 epsg (SRID): 4674
temp_sf <- harmonize_projection(temp_sf)
st_crs(temp_sf)
###### 5. remove Z dimension of spatial data-----------------
temp_sf <- temp_sf %>% st_sf() %>% st_zm( drop = T, what = "ZM")
head(temp_sf)
###### 6. fix eventual topology issues in the data-----------------
temp_sf <- sf::st_make_valid(temp_sf)
###### convert to MULTIPOLYGON -----------------
temp_sf <- to_multipolygon(temp_sf)
###### 7. generate a lighter version of the dataset with simplified borders -----------------
# skip this step if the dataset is made of points, regular spatial grids or rater data
# simplify
temp_sf_simplified <- st_transform(temp_sf, crs=3857) %>%
sf::st_simplify(preserveTopology = T, dTolerance = 100) %>% st_transform(crs=4674)
###### 8. Clean data set and save it -----------------
# save original and simplified datasets
sf::st_write(temp_sf,  paste0("./shapes_in_sf_cleaned/", year,"/", state,".gpkg") )
sf::st_write(temp_sf_simplified,paste0("./shapes_in_sf_cleaned/", year,"/", state,"_simplified.gpkg") )
}
i <- map_files[5]
i
message(paste0('working on', i))
# get year and state
year <- substr(i, 24,27)
state <- substr(i, 29,30) %>% toupper()
# part1 - get names of regions --------------------------------------
mp <- basic_read_map( i )
name_health_region <- attr(mp,"region.name")
code_health_region <- attr(mp,"region.id")
# part2 - get regions as sf objects ---------------------------------
o <- maptools:::readMAP2polylist( i )
oo <- maptools:::.makePolylistValid(o)
ooo <- maptools:::.polylist2SpP(oo, tol=.Machine$double.eps^(1/4))
df <- data.frame(code_health_region=code_health_region, row.names=code_health_region, name_health_region=name_health_region, stringsAsFactors=FALSE)
res <- SpatialPolygonsDataFrame(ooo, data=df)
# fix “orphaned hole” in a polygon
slot(res, "polygons") <- lapply(slot(res, "polygons"), checkPolygonsHoles)
# convert to sf
temp_sf <- st_as_sf(res)
# fix row names
rownames(temp_sf) <- 1:nrow(temp_sf)
# Add state and region information
#temp_sf <- add_region_info(temp_sf, column='code_health_region')
temp_sf <- add_state_info(temp_sf, column='code_health_region')
# reorder columns
temp_sf <- dplyr::select(temp_sf,
"code_health_region", "name_health_region",
"code_state", "abbrev_state", "name_state", 'geometry')
# convert all factor columns to character
temp_sf <- use_encoding_utf8(temp_sf)
# Harmonize spatial projection CRS, using SIRGAS 2000 epsg (SRID): 4674
temp_sf <- harmonize_projection(temp_sf)
st_crs(temp_sf)
###### 5. remove Z dimension of spatial data-----------------
temp_sf <- temp_sf %>% st_sf() %>% st_zm( drop = T, what = "ZM")
head(temp_sf)
###### 6. fix eventual topology issues in the data-----------------
temp_sf <- sf::st_make_valid(temp_sf)
###### convert to MULTIPOLYGON -----------------
temp_sf <- to_multipolygon(temp_sf)
temp_sf
temp_sf_simplified <- simplify_temp_sf(temp_sf)
# save original and simplified datasets
sf::st_write(temp_sf,  paste0("./shapes_in_sf_cleaned/", year,"/", state,".gpkg") )
sf::st_write(temp_sf_simplified,paste0("./shapes_in_sf_cleaned/", year,"/", state,"_simplified.gpkg") )
year
map_files
pbapply::pblapply(map_files, prep_map)
# create empty metadata
metadata <- data.frame(matrix(ncol = 5, nrow = 0))
colnames(metadata) <- c("geo","year","code","download_path","code_abrev")
# list all data files available in the geobr package
geo=list.files("//storage1/geobr/data_gpkg")
# populate the metadata table
for (a in geo) {    # a="setor_censitario"
ano=list.files(paste("//storage1/geobr/data_gpkg",a,sep="/"))
for (b in ano) { # b=2000
estado=list.files(paste("//storage1/geobr/data_gpkg",a,b,sep="/"))
for (c in estado) { #c="Urbano"
if (c=="Urbano"|c=="Rural"){
estado2=list.files(paste("//storage1/geobr/data_gpkg",a,b,c,sep="/"))
for (d in estado2) { #d=estado2[1]
if (c=="Urbano") {
metadata[nrow(metadata) + 1,] = list(a,b,paste0("U",substr(d, 1, 2)),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,d,sep="/"))
}
if (c=="Rural") {
metadata[nrow(metadata) + 1,] = list(a,b,paste0("R",substr(d, 1, 2)),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,d,sep="/"))
}
}
} else {
metadata[nrow(metadata) + 1,] = list(a,b,substr(c, 1, 2),paste("http://www.ipea.gov.br/geobr/data_gpkg",a,b,c,sep="/"))}
}
}
}
subset(metadata, geo=="health_region")
# get code abbreviations
library(data.table)
setDT(metadata)
metadata[ grepl("11", substr(code, 1, 3)), code_abrev :=	"RO" ]
metadata[ grepl("12", substr(code, 1, 3)), code_abrev :=	"AC" ]
metadata[ grepl("13", substr(code, 1, 3)), code_abrev :=	"AM" ]
metadata[ grepl("14", substr(code, 1, 3)), code_abrev :=	"RR" ]
metadata[ grepl("15", substr(code, 1, 3)), code_abrev :=	"PA" ]
metadata[ grepl("16", substr(code, 1, 3)), code_abrev :=	"AP" ]
metadata[ grepl("17", substr(code, 1, 3)), code_abrev :=	"TO" ]
metadata[ grepl("21", substr(code, 1, 3)), code_abrev :=	"MA" ]
metadata[ grepl("22", substr(code, 1, 3)), code_abrev :=	"PI" ]
metadata[ grepl("23", substr(code, 1, 3)), code_abrev :=	"CE" ]
metadata[ grepl("24", substr(code, 1, 3)), code_abrev :=	"RN" ]
metadata[ grepl("25", substr(code, 1, 3)), code_abrev :=	"PB" ]
metadata[ grepl("26", substr(code, 1, 3)), code_abrev :=	"PE" ]
metadata[ grepl("27", substr(code, 1, 3)), code_abrev :=	"AL" ]
metadata[ grepl("28", substr(code, 1, 3)), code_abrev :=	"SE" ]
metadata[ grepl("29", substr(code, 1, 3)), code_abrev :=	"BA" ]
metadata[ grepl("31", substr(code, 1, 3)), code_abrev :=	"MG" ]
metadata[ grepl("32", substr(code, 1, 3)), code_abrev :=	"ES" ]
metadata[ grepl("33", substr(code, 1, 3)), code_abrev :=	"RJ" ]
metadata[ grepl("35", substr(code, 1, 3)), code_abrev :=	"SP" ]
metadata[ grepl("41", substr(code, 1, 3)), code_abrev :=	"PR" ]
metadata[ grepl("42", substr(code, 1, 3)), code_abrev :=	"SC" ]
metadata[ grepl("43", substr(code, 1, 3)), code_abrev :=	"RS" ]
metadata[ grepl("50", substr(code, 1, 3)), code_abrev :=	"MS" ]
metadata[ grepl("51", substr(code, 1, 3)), code_abrev :=	"MT" ]
metadata[ grepl("52", substr(code, 1, 3)), code_abrev :=	"GO" ]
metadata[ grepl("53", substr(code, 1, 3)), code_abrev :=	"DF" ]
# to avoid conflict with data.table
metadata <- as.data.frame(metadata)
table(metadata$geo)
table(metadata$year)
subset(metadata, geo == 'metropolitan_area')
subset(metadata, geo == 'health_region')
data.table::fwrite(metadata,"//storage1/geobr/metadata/metadata_gpkg.csv")
library(geobr)
states <- read_state(year=2019)
head(states)
system("R CMD build . --resave-data") # build tar.gz
library(geobr)
system("R CMD build . --resave-data") # build tar.gz
